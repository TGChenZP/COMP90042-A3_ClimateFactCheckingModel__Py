{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 4.3 Retrieval SBERT"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17934,"status":"ok","timestamp":1683680300079,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"pBV7EEw8ws--","outputId":"e5f45c59-1720-40e9-d43f-d7e9125e74b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Read in Data"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1683680300081,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"IvlHUjGBxi6U"},"outputs":[],"source":["import json\n","import numpy as np\n","import gc\n","import pickle"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1859,"status":"ok","timestamp":1683680301923,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"SxJxwC3uxAHJ"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/curated/train_claims2.json') as f:\n","    train_claims = json.load(f)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683680301924,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"WnJs6bPCxdS-"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/raw/dev-claims.json') as f:\n","    dev_claims = json.load(f)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":518,"status":"ok","timestamp":1683680302437,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"yIERH2G4LB2S"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/curated/test_claims2.json') as f:\n","    test_claims = json.load(f)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":346,"status":"ok","timestamp":1683680302781,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"fjY4K8Xn82mJ"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/raw/test-claims-unlabelled.json') as f:\n","    future_claims = json.load(f)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5224,"status":"ok","timestamp":1683680307997,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"3gJUbs3YxsS2"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/raw/evidence.json') as f:\n","    evidence = json.load(f)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683680307998,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"qu3MUOzgzok0"},"outputs":[],"source":["import random\n","random.seed(19260817)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Reduce claims"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683680307999,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"FRx-o_iL3wkT"},"outputs":[],"source":["evid_id_list = [evid_id for evid_id in evidence]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Create dataset used to train retriever"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683680307999,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"aC_RdtG1tbmA"},"outputs":[],"source":["NEG_SAMPLE_FACTOR = 1"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1683680308000,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"6aGfiIv-ynQ3"},"outputs":[],"source":["training_data = []\n","\n","for id in train_claims:\n","\n","  claim_text = train_claims[id]['claim_text']\n","\n","  n_evid = len(train_claims[id]['evidences'])\n","\n","  for evid_id in train_claims[id]['evidences']:\n","    evid_text = evidence[evid_id]\n","\n","    training_data.append((((claim_text, evid_text)), 1))\n","  \n","  #negative sampling\n","  neg_sampled = 0\n","  while neg_sampled < n_evid * NEG_SAMPLE_FACTOR:\n","    sampled_neg_evid_id = random.choice(evid_id_list)\n","    if sampled_neg_evid_id not in train_claims[id]['evidences']:\n","      neg_sampled += 1\n","      evid_text = evidence[sampled_neg_evid_id]\n","\n","      training_data.append((((claim_text, evid_text)), 0))"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683680308000,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"fjkog1CQz8IN"},"outputs":[],"source":["dev_data = []\n","\n","for id in dev_claims:\n","\n","  claim_text = dev_claims[id]['claim_text']\n","\n","  n_evid = len(dev_claims[id]['evidences'])\n","\n","  for evid_id in dev_claims[id]['evidences']:\n","    evid_text = evidence[evid_id]\n","\n","    dev_data.append((((claim_text, evid_text)), 1))\n","  \n","  #negative sampling\n","  neg_sampled = 0\n","  while neg_sampled < n_evid * NEG_SAMPLE_FACTOR:\n","    sampled_neg_evid_id = random.choice(evid_id_list)\n","    if sampled_neg_evid_id not in dev_claims[id]['evidences']:\n","      neg_sampled += 1\n","      evid_text = evidence[sampled_neg_evid_id]\n","\n","      dev_data.append((((claim_text, evid_text)), 0))"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683680308000,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"mYCdTk7kK7jr"},"outputs":[],"source":["test_data = []\n","\n","for id in test_claims:\n","\n","  claim_text = test_claims[id]['claim_text']\n","\n","  n_evid = len(test_claims[id]['evidences'])\n","\n","  for evid_id in test_claims[id]['evidences']:\n","    evid_text = evidence[evid_id]\n","\n","    test_data.append((((claim_text, evid_text)), 1))\n","  \n","  #negative sampling\n","  neg_sampled = 0\n","  while neg_sampled < n_evid * NEG_SAMPLE_FACTOR:\n","    sampled_neg_evid_id = random.choice(evid_id_list)\n","    if sampled_neg_evid_id not in test_claims[id]['evidences']:\n","      neg_sampled += 1\n","      evid_text = evidence[sampled_neg_evid_id]\n","\n","      test_data.append((((claim_text, evid_text)), 0))"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8745,"status":"ok","timestamp":1683680316729,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"BA0eew_Zxs0O","outputId":"4a513cad-e2b5-4223-81a2-1324ab61c729"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n","Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["!pip install torch torchvision transformers"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Build model, dataloader etc"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":4951,"status":"ok","timestamp":1683680321669,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"6ACUDqscx48V"},"outputs":[],"source":["from transformers import BertModel"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["871eb0a67a20437eb22f5fb68697a60e","76b26c4a47b84d999df10a93c0c19353","db9877b7918547dc8cf4f2f84962c709","84f2bc4362c3435b9ec93223cd0ce3bf","b9f3ec75d92c48d5b91c40fe263c71d1","61da5e0d42004741a05a54368aa5bf62","64e18086a8ba433c934c6380e7e57369","ac67650483254d4480dc9ce1561306ec","960c0e13f8eb436bae66c1380cd57d64","870be3722d8e4f65bc06609b682ead62","f4da26461d544aefacf7718f7ba1b118","9ced6bf3c6524fcaaec3057e189b3a75","fc608abba2ce46889cdef4353437e729","58f690aaf6a24b8f9cffd44209a6f06d","544c3deb8b6e4a52b00942eb2e0d7671","e0a2b5c2e31a4c22a1aaa0bdf41aeca3","2964054e70244d55a1185ae0288024ba","f8c4c7f2cc214037aabd6ce10654991e","2d731007bf9e4ace80b12b1654b69b70","a4e05c6a162a4da39a8e78604401669f","b8ee15200b3842818a3fdaa3e713adbd","234cfe7030464869b7696b5166c1482f","be2faa9c24134b8291a39dccd5fb533e","b18cdacecef340bbb9af72a89bede5e1","33f3e88a90d24832b79279fa2cec02d3","5b18df5a30b94c08bdae9d4ef44d8ebe","fde1c86393794e9f81e8dc077596df25","926278e7b5474fe88d14d54f9ce269ab","0b0b2b1ac0554e06958a5b8e77d3b784","daa34368dc314890b53d9d91039378fe","60cc7066aa324e789034d3146755855f","54038c5f53ed4fc2baccaf3978458b10","f6186618276d41d6a5f1949396f2f063"]},"executionInfo":{"elapsed":678,"status":"ok","timestamp":1683680322342,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"jwvoS1RjyJw3","outputId":"18f717c5-872a-4025-d08d-8aab840a2967"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"871eb0a67a20437eb22f5fb68697a60e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ced6bf3c6524fcaaec3057e189b3a75","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"be2faa9c24134b8291a39dccd5fb533e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":518,"status":"ok","timestamp":1683680322854,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"HuIdphoS21tC"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from transformers import BertTokenizer\n","import pandas as pd\n","\n","class Dataset():\n","\n","    def __init__(self, data, maxlen):\n","\n","        #Store the contents of the file in a pandas dataframe\n","        self.data = data\n","\n","        #Initialize the BERT tokenizer\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","        self.maxlen = maxlen\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","\n","        #Selecting the sentence and label at the specified index in the data frame\n","        sentence1 = self.data[index][0][0]\n","        sentence2 = self.data[index][0][1]\n","        label = self.data[index][1]\n","\n","        #Preprocessing the text to be suitable for BERT\n","        tokens1 = tokenizer.tokenize(sentence1)\n","        tokens2 = tokenizer.tokenize(sentence2)\n","        tokens1 = ['[CLS]'] + tokens1 + ['[SEP]']\n","        tokens2 = ['[CLS]'] + tokens2 + ['[SEP]']\n","        if len(tokens1) < self.maxlen:\n","            tokens1 = tokens1 + ['[PAD]' for _ in range(self.maxlen - len(tokens1))] #Padding sentences\n","        else:\n","            tokens1 = tokens1[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n","\n","        if len(tokens2) < self.maxlen:\n","            tokens2 = tokens2 + ['[PAD]' for _ in range(self.maxlen - len(tokens2))] #Padding sentences\n","        else:\n","            tokens2 = tokens2[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n","\n","        tokens_ids1 = self.tokenizer.convert_tokens_to_ids(tokens1) #Obtaining the indices of the tokens in the BERT Vocabulary\n","        tokens_ids_tensor1 = torch.tensor(tokens_ids1) #Converting the list to a pytorch tensor\n","\n","        tokens_ids2 = self.tokenizer.convert_tokens_to_ids(tokens2) #Obtaining the indices of the tokens in the BERT Vocabulary\n","        tokens_ids_tensor2 = torch.tensor(tokens_ids2) #Converting the list to a pytorch tensor\n","\n","        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n","        attn_mask1 = (tokens_ids_tensor1 != 0).long()\n","        attn_mask2 = (tokens_ids_tensor2 != 0).long()\n","\n","\n","\n","        return tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2,  label"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":421,"status":"ok","timestamp":1683680323266,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"qvOcemHR_bHt"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","#Creating instances of training and development set\n","#maxlen sets the maximum length a sentence can have\n","#any sentence longer than this length is truncated to the maxlen size\n","train_set = Dataset(training_data, maxlen = 512)\n","dev_set = Dataset(dev_data, maxlen = 512)\n","test_set = Dataset(test_data, maxlen = 512)\n","\n","#Creating intsances of training and development dataloaders\n","train_loader = DataLoader(train_set, batch_size = 4, shuffle = True, num_workers = 2)\n","dev_loader = DataLoader(dev_set, batch_size = 4, shuffle = True, num_workers = 2)\n","test_loader = DataLoader(test_set, batch_size = 4, shuffle = True, num_workers = 2)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1683680323268,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"srZ-42Pz_oyO"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from transformers import BertModel\n","\n","class RelatednessClassifier(nn.Module):\n","\n","    def __init__(self):\n","        super(RelatednessClassifier, self).__init__()\n","        #Instantiating BERT model object \n","        self.bert_layer1 = BertModel.from_pretrained('bert-base-uncased')\n","        self.bert_layer2 = BertModel.from_pretrained('bert-base-uncased')\n","\n","        \n","        #Classification layer\n","        #input dimension is 768 because [CLS] embedding has a dimension of 768\n","        #output dimension is 1 because we're working with a binary classification problem\n","        self.cls_layer = nn.Linear(1537, 1)\n","\n","    def forward(self, seq1, attn_masks1, seq2, attn_masks2):\n","        '''\n","        Inputs:\n","            -seq : Tensor of shape [B, T] containing token ids of sequences\n","            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n","        '''\n","        batch_size = seq1.size(0)\n","        #Feeding the input to BERT model to obtain contextualized representations\n","        claim_outputs = self.bert_layer1(seq1, attention_mask = attn_masks1, return_dict=True)\n","        claim_cont_reps = claim_outputs.last_hidden_state\n","\n","        #Obtaining the representation of [CLS] head (the first token)\n","        claim_cls_reps = claim_cont_reps[:, 0]\n","\n","        #Feeding the input to BERT model to obtain contextualized representations\n","        evid_outputs = self.bert_layer2(seq2, attention_mask = attn_masks2, return_dict=True)\n","        evid_cont_reps = evid_outputs.last_hidden_state\n","\n","        #Obtaining the representation of [CLS] head (the first token)\n","        evid_cls_reps = evid_cont_reps[:, 0]\n","\n","        # Concatenate the two output tensors along the last dimension (i.e., the features dimension)\n","        concat_output = torch.cat((claim_cls_reps, evid_cls_reps), dim=-1)\n","\n","        # Calculate the Euclidean distance between the two output tensors and flatten the result\n","        distances = []\n","        for i in range(batch_size):\n","            distance = torch.dist(claim_cls_reps[i], evid_cls_reps[i], p=2)\n","            distances.append(distance)\n","        distances = torch.flatten(torch.stack(distances)).unsqueeze(1)\n","\n","        # Concatenate the flattened distance with the concatenated output tensor\n","        concat_output = torch.cat((concat_output, distances), dim=-1)\n","\n","        #Feeding cls_rep to the classifier layer\n","        logits = self.cls_layer(concat_output)\n","\n","        return logits\n","    \n","\n","    def get_claim_embedding(self, seq1, attn_masks1):\n","        #Feeding the input to BERT model to obtain contextualized representations\n","        claim_outputs = self.bert_layer1(seq1, attention_mask = attn_masks1, return_dict=True)\n","        claim_cont_reps = claim_outputs.last_hidden_state\n","\n","        #Obtaining the representation of [CLS] head (the first token)\n","        claim_cls_reps = claim_cont_reps[:, 0]\n","\n","        return claim_cls_reps\n","    \n","\n","    def get_evid_embedding(self, seq2, attn_masks2):\n","        #Feeding the input to BERT model to obtain contextualized representations\n","        evid_outputs = self.bert_layer2(seq2, attention_mask = attn_masks2, return_dict=True)\n","        evid_cont_reps = evid_outputs.last_hidden_state\n","\n","        #Obtaining the representation of [CLS] head (the first token)\n","        evid_cls_reps = evid_cont_reps[:, 0]\n","\n","        return evid_cls_reps\n","    \n","\n","    def neural_layer(self, claim_cls_reps, evid_cls_reps, batch_size):\n","\n","        # Concatenate the two output tensors along the last dimension (i.e., the features dimension)\n","        concat_output = torch.cat((claim_cls_reps, evid_cls_reps), dim=-1)\n","\n","        # Calculate the Euclidean distance between the two output tensors and flatten the result\n","        distances = []\n","        for i in range(batch_size):\n","            distance = torch.dist(claim_cls_reps[i], evid_cls_reps[i], p=2)\n","            distances.append(distance)\n","        if batch_size == 1:\n","          distances = torch.flatten(torch.stack(distances))\n","        else:\n","          distances = torch.flatten(torch.stack(distances)).unsqueeze(1)\n","\n","        # Concatenate the flattened distance with the concatenated output tensor\n","        concat_output = torch.cat((concat_output, distances), dim=-1)\n","\n","        #Feeding cls_rep to the classifier layer\n","        logits = self.cls_layer(concat_output)\n","\n","        return logits"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1683680323271,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"uJDoCv7AB9B5","outputId":"5faca9ce-c9b6-410e-84fa-3ffd74270f75"},"outputs":[{"data":{"text/plain":["12"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208,"referenced_widgets":["e8ef2735a9464883a5ea748e26f610be","c0e55de10cfb41339625a4f4aa136def","7d95a0e580834f85b32f5e7134973f23","8ff3fdcfa54542578b298d5fb9a4038a","e955ffd79a9a4b8da9d532dfebbe0d48","7d146490eb864ee5a445820bf5ebb06b","56cf6a10e1f34fd892667e26cdaf8a40","a5407f4b1b1a43008cba346c7425c44f","2f754c36328e469ba390d7dc51e55391","a5c70a64dc1047b2b79a451cd7b0733c","82d122bbeb5c447ab07efabba6324b58"]},"executionInfo":{"elapsed":31399,"status":"ok","timestamp":1683680354648,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"fA0faPfGAeLl","outputId":"ae1b3681-fe19-44ed-b210-e57c2f017730"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e8ef2735a9464883a5ea748e26f610be","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Done creating the sentiment classifier.\n"]}],"source":["gpu = 0 #gpu ID\n","\n","print(\"Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\")\n","net = RelatednessClassifier()\n","net.cuda(gpu) #Enable gpu support for the model\n","print(\"Done creating the sentiment classifier.\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Setup Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CGlc0FwVAlHB"},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","criterion = nn.BCEWithLogitsLoss()\n","opti = optim.Adam(net.parameters(), lr = 2e-5)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683621851080,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"L7RR7ohEAnjy"},"outputs":[],"source":["def get_accuracy_from_logits(logits, labels):\n","    probs = torch.sigmoid(logits.unsqueeze(-1))\n","    soft_probs = (probs > 0.5).long()\n","    acc = (soft_probs.squeeze() == labels).float().mean()\n","    return acc\n","\n","def evaluate(net, criterion, dataloader, gpu):\n","    net.eval()\n","\n","    mean_acc, mean_loss = 0, 0\n","    count = 0\n","\n","    with torch.no_grad():\n","        for tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2, label in dataloader:\n","            tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2, label = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu), tokens_ids_tensor2.cuda(gpu), attn_mask2.cuda(gpu), label.cuda(gpu)\n","            logits = net(tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2)\n","            mean_loss += criterion(logits.squeeze(-1), label.float()).item()\n","            mean_acc += get_accuracy_from_logits(logits, label)\n","            count += 1\n","\n","    return mean_acc / count, mean_loss / count"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1683621851080,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"eBze9eaUAqLg"},"outputs":[],"source":["import time\n","\n","def train(net, criterion, opti, train_loader, dev_loader, max_eps, gpu):\n","\n","    best_acc = 0\n","    st = time.time()\n","    for ep in range(max_eps):\n","        \n","        net.train()\n","        for it, (tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2, label) in enumerate(train_loader):\n","            #Clear gradients\n","            opti.zero_grad()  \n","            #Converting these to cuda tensors\n","            tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2, label = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu), tokens_ids_tensor2.cuda(gpu), attn_mask2.cuda(gpu), label.cuda(gpu)\n","\n","            #Obtaining the logits from the model\n","            logits = net(tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2)\n","\n","            #Computing loss\n","            loss = criterion(logits.squeeze(-1), label.float())\n","\n","            #Backpropagating the gradients\n","            loss.backward()\n","\n","            #Optimization step\n","            opti.step()\n","              \n","            if it % 100 == 0:\n","                \n","                acc = get_accuracy_from_logits(logits, label)\n","                print(\"Iteration {} of epoch {} complete. Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n","                st = time.time()\n","\n","        \n","        dev_acc, dev_loss = evaluate(net, criterion, dev_loader, gpu)\n","        print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(ep, dev_acc, dev_loss))\n","        if dev_acc > best_acc:\n","            print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n","            best_acc = dev_acc\n","            torch.save(net.state_dict(), './drive/My Drive/LAB/COMP90042 A3/models/Retrievers/Retriever_SBert.dat')\n","            torch.save(net, './drive/My Drive/LAB/COMP90042 A3/models/Retrievers/Retriever_SBert.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683510755891,"user":{"displayName":"Ron Chen","userId":"17639042157366273501"},"user_tz":-600},"id":"QtKuWB_yB-JB","outputId":"1e3a9157-1d38-44c0-9c6c-21723a0f976a"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7222831,"status":"ok","timestamp":1683393836234,"user":{"displayName":"zeping chen","userId":"12651116933199519983"},"user_tz":-600},"id":"h5mhGZTSBB2S","outputId":"a6a6ac05-ef6b-43df-d75a-ef41af653ed8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Iteration 0 of epoch 0 complete. Loss: 0.01396762952208519; Accuracy: 1.0; Time taken (s): 0.9922280311584473\n","Iteration 100 of epoch 0 complete. Loss: 0.0022834932897239923; Accuracy: 1.0; Time taken (s): 76.93600249290466\n","Iteration 200 of epoch 0 complete. Loss: 0.03231086581945419; Accuracy: 1.0; Time taken (s): 76.4855682849884\n","Iteration 300 of epoch 0 complete. Loss: 0.048212192952632904; Accuracy: 1.0; Time taken (s): 76.37822246551514\n","Iteration 400 of epoch 0 complete. Loss: 0.025565508753061295; Accuracy: 1.0; Time taken (s): 76.409738779068\n","Iteration 500 of epoch 0 complete. Loss: 0.033778924494981766; Accuracy: 1.0; Time taken (s): 76.39283323287964\n","Iteration 600 of epoch 0 complete. Loss: 0.007882692851126194; Accuracy: 1.0; Time taken (s): 76.2576060295105\n","Iteration 700 of epoch 0 complete. Loss: 0.008956797420978546; Accuracy: 1.0; Time taken (s): 76.21597027778625\n","Iteration 800 of epoch 0 complete. Loss: 0.3136775493621826; Accuracy: 0.75; Time taken (s): 76.29948234558105\n","Iteration 900 of epoch 0 complete. Loss: 0.00133618398103863; Accuracy: 1.0; Time taken (s): 76.43105673789978\n","Iteration 1000 of epoch 0 complete. Loss: 0.0015550781972706318; Accuracy: 1.0; Time taken (s): 76.24177479743958\n","Iteration 1100 of epoch 0 complete. Loss: 0.028913427144289017; Accuracy: 1.0; Time taken (s): 76.16894364356995\n","Iteration 1200 of epoch 0 complete. Loss: 0.021198980510234833; Accuracy: 1.0; Time taken (s): 76.24092769622803\n","Iteration 1300 of epoch 0 complete. Loss: 0.004200247582048178; Accuracy: 1.0; Time taken (s): 76.26612615585327\n","Iteration 1400 of epoch 0 complete. Loss: 0.0048480285331606865; Accuracy: 1.0; Time taken (s): 76.27143931388855\n","Iteration 1500 of epoch 0 complete. Loss: 0.07921405136585236; Accuracy: 1.0; Time taken (s): 76.3897762298584\n","Iteration 1600 of epoch 0 complete. Loss: 0.0049992818385362625; Accuracy: 1.0; Time taken (s): 76.52747821807861\n","Iteration 1700 of epoch 0 complete. Loss: 0.02407926879823208; Accuracy: 1.0; Time taken (s): 76.26712083816528\n","Iteration 1800 of epoch 0 complete. Loss: 0.01981627568602562; Accuracy: 1.0; Time taken (s): 75.91686916351318\n","Epoch 0 complete! Development Accuracy: 0.9380080699920654; Development Loss: 0.1698057642168691\n","Best development accuracy improved from 0 to 0.9380080699920654, saving model...\n","Iteration 0 of epoch 1 complete. Loss: 0.16979366540908813; Accuracy: 1.0; Time taken (s): 76.23237204551697\n","Iteration 100 of epoch 1 complete. Loss: 0.010053504258394241; Accuracy: 1.0; Time taken (s): 76.65895962715149\n","Iteration 200 of epoch 1 complete. Loss: 0.001117272418923676; Accuracy: 1.0; Time taken (s): 76.40926051139832\n","Iteration 300 of epoch 1 complete. Loss: 0.004061277024447918; Accuracy: 1.0; Time taken (s): 76.18537330627441\n","Iteration 400 of epoch 1 complete. Loss: 0.012265829369425774; Accuracy: 1.0; Time taken (s): 76.35705518722534\n","Iteration 500 of epoch 1 complete. Loss: 0.002799537032842636; Accuracy: 1.0; Time taken (s): 76.52023553848267\n","Iteration 600 of epoch 1 complete. Loss: 0.003738583065569401; Accuracy: 1.0; Time taken (s): 76.26942086219788\n","Iteration 700 of epoch 1 complete. Loss: 0.001908988575451076; Accuracy: 1.0; Time taken (s): 76.42113280296326\n","Iteration 800 of epoch 1 complete. Loss: 0.005223321262747049; Accuracy: 1.0; Time taken (s): 76.27858805656433\n","Iteration 900 of epoch 1 complete. Loss: 0.02046874165534973; Accuracy: 1.0; Time taken (s): 76.36565518379211\n","Iteration 1000 of epoch 1 complete. Loss: 0.0032320350874215364; Accuracy: 1.0; Time taken (s): 76.22436380386353\n","Iteration 1100 of epoch 1 complete. Loss: 0.00420749606564641; Accuracy: 1.0; Time taken (s): 76.3244149684906\n","Iteration 1200 of epoch 1 complete. Loss: 0.011980479583144188; Accuracy: 1.0; Time taken (s): 76.30819272994995\n","Iteration 1300 of epoch 1 complete. Loss: 0.005268082953989506; Accuracy: 1.0; Time taken (s): 76.27655839920044\n","Iteration 1400 of epoch 1 complete. Loss: 0.002865857444703579; Accuracy: 1.0; Time taken (s): 76.45260858535767\n","Iteration 1500 of epoch 1 complete. Loss: 0.0004942097584716976; Accuracy: 1.0; Time taken (s): 76.29475998878479\n","Iteration 1600 of epoch 1 complete. Loss: 0.0010536196641623974; Accuracy: 1.0; Time taken (s): 76.31296277046204\n","Iteration 1700 of epoch 1 complete. Loss: 0.01576933078467846; Accuracy: 1.0; Time taken (s): 76.33269500732422\n","Iteration 1800 of epoch 1 complete. Loss: 0.32202643156051636; Accuracy: 1.0; Time taken (s): 76.0191421508789\n","Epoch 1 complete! Development Accuracy: 0.9593495726585388; Development Loss: 0.15118819773434974\n","Best development accuracy improved from 0.9380080699920654 to 0.9593495726585388, saving model...\n","Iteration 0 of epoch 2 complete. Loss: 0.004781649447977543; Accuracy: 1.0; Time taken (s): 74.69450330734253\n","Iteration 100 of epoch 2 complete. Loss: 0.008772130124270916; Accuracy: 1.0; Time taken (s): 76.58044290542603\n","Iteration 200 of epoch 2 complete. Loss: 0.003341381438076496; Accuracy: 1.0; Time taken (s): 76.4662344455719\n","Iteration 300 of epoch 2 complete. Loss: 0.0021676705218851566; Accuracy: 1.0; Time taken (s): 76.2536940574646\n","Iteration 400 of epoch 2 complete. Loss: 0.003795676864683628; Accuracy: 1.0; Time taken (s): 76.22516226768494\n","Iteration 500 of epoch 2 complete. Loss: 0.032507993280887604; Accuracy: 1.0; Time taken (s): 76.29305243492126\n","Iteration 600 of epoch 2 complete. Loss: 0.0026098114904016256; Accuracy: 1.0; Time taken (s): 76.35356903076172\n","Iteration 700 of epoch 2 complete. Loss: 0.0012467814376577735; Accuracy: 1.0; Time taken (s): 76.40714287757874\n","Iteration 800 of epoch 2 complete. Loss: 0.0005946996388956904; Accuracy: 1.0; Time taken (s): 76.39624810218811\n","Iteration 900 of epoch 2 complete. Loss: 0.013050919398665428; Accuracy: 1.0; Time taken (s): 76.36670303344727\n","Iteration 1000 of epoch 2 complete. Loss: 0.0015266360715031624; Accuracy: 1.0; Time taken (s): 76.23268342018127\n","Iteration 1100 of epoch 2 complete. Loss: 0.0006576739251613617; Accuracy: 1.0; Time taken (s): 76.43105125427246\n","Iteration 1200 of epoch 2 complete. Loss: 0.00039133470272645354; Accuracy: 1.0; Time taken (s): 76.42544174194336\n","Iteration 1300 of epoch 2 complete. Loss: 0.02699493244290352; Accuracy: 1.0; Time taken (s): 76.35974359512329\n","Iteration 1400 of epoch 2 complete. Loss: 0.0036865328438580036; Accuracy: 1.0; Time taken (s): 76.3695421218872\n","Iteration 1500 of epoch 2 complete. Loss: 0.02631862461566925; Accuracy: 1.0; Time taken (s): 76.24834656715393\n","Iteration 1600 of epoch 2 complete. Loss: 0.0034482055343687534; Accuracy: 1.0; Time taken (s): 76.38932967185974\n","Iteration 1700 of epoch 2 complete. Loss: 0.007063721306622028; Accuracy: 1.0; Time taken (s): 76.43414783477783\n","Iteration 1800 of epoch 2 complete. Loss: 0.0216799508780241; Accuracy: 1.0; Time taken (s): 76.10702967643738\n","Epoch 2 complete! Development Accuracy: 0.9552845358848572; Development Loss: 0.14827275851945987\n","Iteration 0 of epoch 3 complete. Loss: 0.007185920141637325; Accuracy: 1.0; Time taken (s): 67.64068007469177\n","Iteration 100 of epoch 3 complete. Loss: 0.0006913066026754677; Accuracy: 1.0; Time taken (s): 76.35908007621765\n","Iteration 200 of epoch 3 complete. Loss: 0.011446411721408367; Accuracy: 1.0; Time taken (s): 76.29135012626648\n","Iteration 300 of epoch 3 complete. Loss: 0.002790106926113367; Accuracy: 1.0; Time taken (s): 76.27866077423096\n","Iteration 400 of epoch 3 complete. Loss: 0.0006056292331777513; Accuracy: 1.0; Time taken (s): 76.28362607955933\n","Iteration 500 of epoch 3 complete. Loss: 0.0016842706827446818; Accuracy: 1.0; Time taken (s): 76.36768507957458\n","Iteration 600 of epoch 3 complete. Loss: 0.006286245305091143; Accuracy: 1.0; Time taken (s): 76.44847249984741\n","Iteration 700 of epoch 3 complete. Loss: 0.00023377456818707287; Accuracy: 1.0; Time taken (s): 76.43369317054749\n","Iteration 800 of epoch 3 complete. Loss: 0.0008619814761914313; Accuracy: 1.0; Time taken (s): 76.38774013519287\n","Iteration 900 of epoch 3 complete. Loss: 0.0022953429725021124; Accuracy: 1.0; Time taken (s): 76.27138996124268\n","Iteration 1000 of epoch 3 complete. Loss: 0.002839515218511224; Accuracy: 1.0; Time taken (s): 76.36773824691772\n","Iteration 1100 of epoch 3 complete. Loss: 0.0016139962244778872; Accuracy: 1.0; Time taken (s): 76.48267722129822\n","Iteration 1200 of epoch 3 complete. Loss: 0.018651464954018593; Accuracy: 1.0; Time taken (s): 76.31175947189331\n","Iteration 1300 of epoch 3 complete. Loss: 0.0018427243921905756; Accuracy: 1.0; Time taken (s): 76.33983039855957\n","Iteration 1400 of epoch 3 complete. Loss: 0.000444785226136446; Accuracy: 1.0; Time taken (s): 76.30009770393372\n","Iteration 1500 of epoch 3 complete. Loss: 0.0012658947380259633; Accuracy: 1.0; Time taken (s): 76.19482111930847\n","Iteration 1600 of epoch 3 complete. Loss: 0.00034692796180024743; Accuracy: 1.0; Time taken (s): 76.36834454536438\n","Iteration 1700 of epoch 3 complete. Loss: 1.9721918106079102; Accuracy: 0.75; Time taken (s): 76.42533683776855\n","Iteration 1800 of epoch 3 complete. Loss: 0.016791732981801033; Accuracy: 1.0; Time taken (s): 76.0644907951355\n","Epoch 3 complete! Development Accuracy: 0.9390243291854858; Development Loss: 0.25220804892769516\n","Iteration 0 of epoch 4 complete. Loss: 0.0010644204448908567; Accuracy: 1.0; Time taken (s): 67.53409171104431\n","Iteration 100 of epoch 4 complete. Loss: 0.0006771997432224452; Accuracy: 1.0; Time taken (s): 76.34225177764893\n","Iteration 200 of epoch 4 complete. Loss: 0.004772494081407785; Accuracy: 1.0; Time taken (s): 76.22749209403992\n","Iteration 300 of epoch 4 complete. Loss: 0.0007660359842702746; Accuracy: 1.0; Time taken (s): 76.26096749305725\n","Iteration 400 of epoch 4 complete. Loss: 0.0007325424812734127; Accuracy: 1.0; Time taken (s): 76.34888029098511\n","Iteration 500 of epoch 4 complete. Loss: 0.0005412612808868289; Accuracy: 1.0; Time taken (s): 76.26515436172485\n","Iteration 600 of epoch 4 complete. Loss: 0.0008163548191078007; Accuracy: 1.0; Time taken (s): 76.24594736099243\n","Iteration 700 of epoch 4 complete. Loss: 0.0003692990867421031; Accuracy: 1.0; Time taken (s): 76.33362627029419\n","Iteration 800 of epoch 4 complete. Loss: 0.0004345026973169297; Accuracy: 1.0; Time taken (s): 76.34814143180847\n","Iteration 900 of epoch 4 complete. Loss: 0.0005379875656217337; Accuracy: 1.0; Time taken (s): 76.2677264213562\n","Iteration 1000 of epoch 4 complete. Loss: 0.0004840613983105868; Accuracy: 1.0; Time taken (s): 76.20138216018677\n","Iteration 1100 of epoch 4 complete. Loss: 0.00040327178430743515; Accuracy: 1.0; Time taken (s): 76.21728587150574\n","Iteration 1200 of epoch 4 complete. Loss: 0.0005327280960045755; Accuracy: 1.0; Time taken (s): 76.25824880599976\n","Iteration 1300 of epoch 4 complete. Loss: 0.0003478203434497118; Accuracy: 1.0; Time taken (s): 76.31116843223572\n","Iteration 1400 of epoch 4 complete. Loss: 0.0007526559056714177; Accuracy: 1.0; Time taken (s): 76.36233925819397\n","Iteration 1500 of epoch 4 complete. Loss: 0.0005576753756031394; Accuracy: 1.0; Time taken (s): 76.27029943466187\n","Iteration 1600 of epoch 4 complete. Loss: 0.0005360668292269111; Accuracy: 1.0; Time taken (s): 76.2140645980835\n","Iteration 1700 of epoch 4 complete. Loss: 0.0020943775307387114; Accuracy: 1.0; Time taken (s): 76.27462911605835\n","Iteration 1800 of epoch 4 complete. Loss: 0.0007127102580852807; Accuracy: 1.0; Time taken (s): 75.95335292816162\n","Epoch 4 complete! Development Accuracy: 0.9410568475723267; Development Loss: 0.2580065278958589\n"]}],"source":["num_epoch = 5\n","\n","#fine-tune the model\n","train(net, criterion, opti, train_loader, dev_loader, num_epoch, gpu)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Read In Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11339,"status":"ok","timestamp":1683379452403,"user":{"displayName":"Lang Chen","userId":"02743582657302157093"},"user_tz":-600},"id":"XExrRgJ6r1Uv","outputId":"0ef7c165-6624-4dc9-cfe3-25725b11e238"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["net.load_state_dict(torch.load('./drive/My Drive/LAB/COMP90042 A3/models/Retrievers/Retriever_SBert.dat'))"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":12118,"status":"ok","timestamp":1683680366762,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"lNE4FUvKAor6"},"outputs":[],"source":["net = torch.load('./drive/My Drive/LAB/COMP90042 A3/models/Retrievers/Retriever_SBert.pt')"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683680366763,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"HzjUr6tcAtxL","outputId":"87d621d0-e960-438b-b485-e2d79ebbb59e"},"outputs":[{"data":{"text/plain":["RelatednessClassifier(\n","  (bert_layer1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (bert_layer2): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (cls_layer): Linear(in_features=1537, out_features=1, bias=True)\n",")"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["net.eval()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kuy1woNGfkHj"},"source":["## Make Predictions (to get Retrievals)"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1683680366764,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"rEwnE7-zd92B"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from transformers import BertTokenizer\n","import pandas as pd\n","\n","class EmbeddingDataset():\n","\n","    def __init__(self, data, maxlen):\n","\n","        #Store the contents of the file in a pandas dataframe\n","        self.data = data\n","\n","        #Initialize the BERT tokenizer\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","        self.maxlen = maxlen\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","\n","        #Selecting the sentence and label at the specified index in the data frame\n","        id = self.data[index][0]\n","        sentence1 = self.data[index][1]\n","\n","        #Preprocessing the text to be suitable for BERT\n","        tokens1 = tokenizer.tokenize(sentence1)\n","        tokens1 = ['[CLS]'] + tokens1 + ['[SEP]']\n","        if len(tokens1) < self.maxlen:\n","            tokens1 = tokens1 + ['[PAD]' for _ in range(self.maxlen - len(tokens1))] #Padding sentences\n","        else:\n","            tokens1 = tokens1[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n","\n","        tokens_ids1 = self.tokenizer.convert_tokens_to_ids(tokens1) #Obtaining the indices of the tokens in the BERT Vocabulary\n","        tokens_ids_tensor1 = torch.tensor(tokens_ids1) #Converting the list to a pytorch tensor\n","\n","        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n","        attn_mask1 = (tokens_ids_tensor1 != 0).long()\n","\n","\n","\n","        return id, tokens_ids_tensor1, attn_mask1"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":1882,"status":"ok","timestamp":1683680368629,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"rlkgQRGcf0IH"},"outputs":[],"source":["dev_embedding_data = []\n","\n","for id in dev_claims:\n","\n","  claim_text = dev_claims[id]['claim_text']\n","\n","  dev_embedding_data.append((id, claim_text))\n","\n","\n","test_embedding_data = []\n","\n","for id in test_claims:\n","\n","  claim_text = test_claims[id]['claim_text']\n","\n","  test_embedding_data.append((id, claim_text))\n","\n","\n","future_embedding_data = []\n","\n","for id in future_claims:\n","\n","  claim_text = future_claims[id]['claim_text']\n","\n","  future_embedding_data.append((id, claim_text))\n","  \n","\n","evid_embedding_data = []\n","for evid in evidence:\n","  evid_text = evidence[evid]\n","\n","  evid_embedding_data.append((evid, evid_text))"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683680368629,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"4w8-BFJ0gzDx"},"outputs":[],"source":["dev_embed_set = EmbeddingDataset(dev_embedding_data, maxlen = 512)\n","test_embed_set = EmbeddingDataset(test_embedding_data, maxlen = 512)\n","future_embed_set = EmbeddingDataset(future_embedding_data, maxlen = 512)\n","evid_embed_set = EmbeddingDataset(evid_embedding_data, maxlen = 512)\n","\n","#Creating intsances of training and development dataloaders\n","dev_embed_loader = DataLoader(dev_embed_set, batch_size = 4, shuffle = False, num_workers = 2)\n","test_embed_loader = DataLoader(test_embed_set, batch_size = 4, shuffle = False, num_workers = 2)\n","future_embed_loader = DataLoader(future_embed_set, batch_size = 4, shuffle = False, num_workers = 2)\n","evid_embed_loader = DataLoader(evid_embed_set, batch_size = 4, shuffle = False, num_workers = 2)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1683680369004,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"FBJTIV3hDjp9","outputId":"c3c4dc82-4a0e-4612-b67a-2a685df13c52"},"outputs":[{"data":{"text/plain":["33"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PPqoW-KUhP71"},"outputs":[],"source":["dev_embed = {}\n","\n","for id, tokens_ids_tensor1, attn_mask1 in dev_embed_loader:\n","  tokens_ids_tensor1, attn_mask1 = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu)\n","  embed = net.get_claim_embedding(tokens_ids_tensor1, attn_mask1)\n","\n","  embed = embed.tolist()\n","  for i in range(len(id)):\n","      dev_embed[id[i]] = embed[i]\n","\n","with open('./drive/My Drive/LAB/COMP90042 A3/dev_embed.json', 'w') as f:\n","  json.dump(dev_embed, f)"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":5728,"status":"ok","timestamp":1683680374729,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"9dIvNFhOo_7r"},"outputs":[],"source":["test_embed = {}\n","\n","for id, tokens_ids_tensor1, attn_mask1 in test_embed_loader:\n","  tokens_ids_tensor1, attn_mask1 = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu)\n","  embed = net.get_claim_embedding(tokens_ids_tensor1, attn_mask1)\n","\n","  embed = embed.tolist()\n","  for i in range(len(id)):\n","      test_embed[id[i]] = embed[i]\n","\n","with open('./drive/My Drive/LAB/COMP90042 A3/test_embed.json', 'w') as f:\n","  json.dump(test_embed, f)"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":5535,"status":"ok","timestamp":1683680380246,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"okI682uUpNSU"},"outputs":[],"source":["future_embed = {}\n","\n","for id, tokens_ids_tensor1, attn_mask1 in future_embed_loader:\n","  tokens_ids_tensor1, attn_mask1 = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu)\n","  embed = net.get_claim_embedding(tokens_ids_tensor1, attn_mask1)\n","\n","  embed = embed.tolist()\n","  for i in range(len(id)):\n","      future_embed[id[i]] = embed[i]\n","\n","with open('./drive/My Drive/LAB/COMP90042 A3/future_embed.json', 'w') as f:\n","  json.dump(future_embed, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683421771215,"user":{"displayName":"Ron Chen","userId":"17639042157366273501"},"user_tz":-600},"id":"QjS8qslqqY17","outputId":"45fde236-41df-4975-8f26-c38c2a78941f"},"outputs":[{"data":{"text/plain":["67"]},"execution_count":43,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28946050,"status":"ok","timestamp":1683577558045,"user":{"displayName":"Ron Chen","userId":"17639042157366273501"},"user_tz":-600},"id":"E35T7-Rmh5pw","outputId":"43ef9df2-0eea-4897-df9a-51d71434a64f"},"outputs":[{"name":"stdout","output_type":"stream","text":["pass 6400\n","pass 12800\n","pass 19200\n","pass 25600\n","pass 32000\n","pass 38400\n","pass 44800\n","pass 51200\n","pass 57600\n","pass 64000\n","pass 70400\n","pass 76800\n","pass 83200\n","pass 89600\n","pass 96000\n","pass 102400\n","pass 108800\n","pass 115200\n","pass 121600\n","pass 128000\n","pass 134400\n","pass 140800\n","pass 147200\n","pass 153600\n","pass 160000\n","pass 166400\n","pass 172800\n","179200\n","185600\n","192000\n","198400\n","204800\n","211200\n","217600\n","224000\n","230400\n","236800\n","243200\n","249600\n","256000\n","262400\n","268800\n","275200\n","281600\n","288000\n","294400\n","300800\n","302207\n"]}],"source":["evid_embed = {}\n","j = 0\n","for id, tokens_ids_tensor1, attn_mask1 in evid_embed_loader:\n","\n","  if j <= 172800:\n","    j+=1\n","    if j %6400 == 0:\n","      print('pass', j)\n","\n","    continue\n","\n","  tokens_ids_tensor1, attn_mask1 = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu)\n","  embed = net.get_evid_embedding(tokens_ids_tensor1, attn_mask1)\n","  embed = embed.tolist()\n","\n","  torch.cuda.empty_cache()\n","  gc.collect()\n","\n","  for i in range(len(id)):\n","      evid_embed[id[i]] = embed[i]\n","  \n","  j += 1\n","  if j %6400 == 0:\n","    print(j)\n","    with open(f'./drive/My Drive/LAB/COMP90042 A3/evid_embed{j}.json', 'w') as f:\n","      json.dump(evid_embed, f)\n","      evid_embed = {}\n","\n","print(j)\n","with open(f'./drive/My Drive/LAB/COMP90042 A3/evid_embed{j}.json', 'w') as f:\n","  json.dump(evid_embed, f)\n","  evid_embed = {}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"emwLTm0NNoxk"},"source":["Prediction"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":802,"status":"ok","timestamp":1683680381031,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"mYsBuuRaNqNg"},"outputs":[],"source":["with open('./drive/My Drive/LAB/COMP90042 A3/embeddings/other_embeddings/dev_embed.json', 'r') as f:\n","  dev_embed = json.load(f)"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":503,"status":"ok","timestamp":1683680381522,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"DHhZ-2h3idQD"},"outputs":[],"source":["with open('./drive/My Drive/LAB/COMP90042 A3/embeddings/other_embeddings/test_embed.json', 'r') as f:\n","  test_embed = json.load(f)"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":511,"status":"ok","timestamp":1683680382032,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"-V8Q4i5did-7"},"outputs":[],"source":["with open('./drive/My Drive/LAB/COMP90042 A3/embeddings/other_embeddings/future_embed.json', 'r') as f:\n","  future_embed = json.load(f)"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1683680382032,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"HziY6f73Okx6"},"outputs":[],"source":["import os\n","evid_embed_list = os.listdir('./drive/My Drive/LAB/COMP90042 A3/embeddings/evid_embedding')"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1683680382034,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"XGPglDLTSebs"},"outputs":[],"source":["class PredictDataset():\n","\n","    def __init__(self, data, maxlen):\n","\n","        #Store the contents of the file in a pandas dataframe\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","\n","        #Selecting the sentence and label at the specified index in the data frame\n","        evid_id = self.data[index][0]\n","        evid_embed_vector = self.data[index][1]\n","\n","        return evid_id, evid_embed_vector"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":478,"status":"ok","timestamp":1683680382497,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"dmbORgGZSgPT","outputId":"9967f282-901b-440d-b8ad-f213b9127ebd"},"outputs":[{"data":{"text/plain":["32"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["BATCH_SIZE = 1024\n","\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1683680382498,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"fgtr55JWgQWd"},"outputs":[],"source":["import copy"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683621884009,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"oMl6aq2zi0Ie"},"outputs":[],"source":["top_5_dev_evid = {}\n","processed_dev_embed = []"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":536,"status":"ok","timestamp":1683680383022,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"NXunl_F3r0EN"},"outputs":[],"source":["with open('./drive/My Drive/LAB/COMP90042 A3/predictions/Retrieval_BERT_dev.pickle', 'rb') as f:\n","    top_5_dev_evid = pickle.load(f)\n","  \n","with open('./drive/My Drive/LAB/COMP90042 A3/embeddings/processed_dev_embed.json', 'r') as f:\n","    processed_dev_embed = json.load(f)"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":316,"status":"ok","timestamp":1683680459671,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"-X8e-06Nb7QC","outputId":"eb5d250d-75e3-474d-92ea-cec3ccde8c17"},"outputs":[{"name":"stdout","output_type":"stream","text":["pass evid_embed6400.json\n","pass evid_embed12800.json\n","pass evid_embed19200.json\n","pass evid_embed25600.json\n","pass evid_embed32000.json\n","pass evid_embed38400.json\n","pass evid_embed44800.json\n","pass evid_embed51200.json\n","pass evid_embed57600.json\n","pass evid_embed64000.json\n","pass evid_embed70400.json\n","pass evid_embed76800.json\n","pass evid_embed83200.json\n","pass evid_embed89600.json\n","pass evid_embed96000.json\n","pass evid_embed102400.json\n","pass evid_embed108800.json\n","pass evid_embed115200.json\n","pass evid_embed121600.json\n","pass evid_embed128000.json\n","pass evid_embed134400.json\n","pass evid_embed140800.json\n","pass evid_embed147200.json\n","pass evid_embed153600.json\n","pass evid_embed160000.json\n","pass evid_embed166400.json\n","pass evid_embed172800.json\n","pass evid_embed179200.json\n","pass evid_embed185600.json\n","pass evid_embed192000.json\n","pass evid_embed198400.json\n","pass evid_embed204800.json\n","pass evid_embed211200.json\n","pass evid_embed217600.json\n","pass evid_embed224000.json\n","pass evid_embed230400.json\n","pass evid_embed236800.json\n","pass evid_embed243200.json\n","pass evid_embed249600.json\n","pass evid_embed256000.json\n","pass evid_embed262400.json\n","pass evid_embed268800.json\n","pass evid_embed275200.json\n","pass evid_embed281600.json\n","pass evid_embed288000.json\n","pass evid_embed294400.json\n","pass evid_embed300800.json\n","pass evid_embed302207.json\n"]}],"source":["for evid_embed_dir in evid_embed_list:\n","\n","  if evid_embed_dir in processed_dev_embed:\n","    print('pass', evid_embed_dir)\n","    continue\n","  \n","  print(evid_embed_dir)\n","  \n","  with open(f'./drive/My Drive/LAB/COMP90042 A3/embeddings/evid_embedding/{evid_embed_dir}', 'r') as f:\n","    evid_embed = json.load(f)\n","    evid_embeds = [(evid_id, evid_embed[evid_id]) for evid_id in evid_embed]\n","\n","    for dev_id in dev_embed:\n","\n","      dev_embed_vector = torch.Tensor([dev_embed[dev_id] for i in range(BATCH_SIZE)])\n","      dev_embed_vector = dev_embed_vector.cuda(gpu)\n","      \n","      if dev_id in top_5_dev_evid:\n","        tmp_evid = copy.deepcopy(top_5_dev_evid[dev_id])\n","      else:\n","        tmp_evid = []\n","\n","      with torch.no_grad():\n","        ids = []\n","        evid_embed_vectors = []\n","        for i in range(len(evid_embeds)):\n","          ids.append(evid_embeds[i][0])\n","          evid_embed_vectors.append(evid_embeds[i][1])\n","        \n","          if (i+1) % BATCH_SIZE == 0:\n","            evid_embed_vectors = torch.Tensor(evid_embed_vectors)\n","            evid_embed_vectors = evid_embed_vectors.cuda(gpu)\n","\n","            predict = net.neural_layer(dev_embed_vector, evid_embed_vectors, BATCH_SIZE).tolist()\n","\n","            for j in range(BATCH_SIZE):\n","              tmp_evid.append((ids[j], predict[j][0]))\n","\n","            ids = []\n","            evid_embed_vectors = []\n","        \n","\n","      tmp_evid.sort(reverse=True, key = lambda x:x[1])\n","      top_5_dev_evid[dev_id] = tmp_evid[:5]\n","\n","  with open('./drive/My Drive/LAB/COMP90042 A3/predictions/Retrieval_BERT_dev.pickle', 'wb') as f:\n","    pickle.dump(top_5_dev_evid, f)\n","  \n","  processed_dev_embed.append(evid_embed_dir)\n","  with open('./drive/My Drive/LAB/COMP90042 A3/embeddings/processed_dev_embed.json', 'w') as f:\n","    json.dump(processed_dev_embed, f)"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":320,"status":"ok","timestamp":1683680431988,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"tpzafv7-m7Kv","outputId":"f0fcb266-da9e-4646-fa38-2293fec78712"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["BATCH_SIZE = 1024\n","\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1683680555460,"user":{"displayName":"Ron Chen","userId":"17292039834848226202"},"user_tz":-600},"id":"JcZFtoAala7p"},"outputs":[],"source":["top_5_test_evid = {}\n","processed_test_embed = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YQcH5SwMmNq1"},"outputs":[],"source":["with open('./drive/My Drive/LAB/COMP90042 A3/predictions/Retrieval_BERT_test.pickle', 'rb') as f:\n","    top_5_test_evid = pickle.load(f)\n","\n","with open('./drive/My Drive/LAB/COMP90042 A3/embeddings/processed_test_embed.json', 'r') as f:\n","    processed_test_embed = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KpfMRPJvldqX","outputId":"61295a70-2a92-4852-a547-444c64e8598e"},"outputs":[{"name":"stdout","output_type":"stream","text":["evid_embed6400.json\n","evid_embed12800.json\n","evid_embed19200.json\n","evid_embed25600.json\n","evid_embed32000.json\n","evid_embed38400.json\n","evid_embed44800.json\n","evid_embed51200.json\n","evid_embed57600.json\n","evid_embed64000.json\n","evid_embed70400.json\n","evid_embed76800.json\n","evid_embed83200.json\n","evid_embed89600.json\n","evid_embed96000.json\n","evid_embed102400.json\n","evid_embed108800.json\n","evid_embed115200.json\n","evid_embed121600.json\n","evid_embed128000.json\n"]}],"source":["for evid_embed_dir in evid_embed_list:\n","\n","  if evid_embed_dir in processed_test_embed:\n","    print('pass', evid_embed_dir)\n","    continue\n","  \n","  print(evid_embed_dir)\n","  \n","  with open(f'./drive/My Drive/LAB/COMP90042 A3/embeddings/evid_embedding/{evid_embed_dir}', 'r') as f:\n","    evid_embed = json.load(f)\n","    evid_embeds = [(evid_id, evid_embed[evid_id]) for evid_id in evid_embed]\n","\n","    for test_id in test_embed:\n","\n","      test_embed_vector = torch.Tensor([test_embed[test_id] for i in range(BATCH_SIZE)])\n","      test_embed_vector = test_embed_vector.cuda(gpu)\n","      \n","      if test_id in top_5_test_evid:\n","        tmp_evid = copy.deepcopy(top_5_test_evid[test_id])\n","      else:\n","        tmp_evid = []\n","\n","      with torch.no_grad():\n","        ids = []\n","        evid_embed_vectors = []\n","        for i in range(len(evid_embeds)):\n","          ids.append(evid_embeds[i][0])\n","          evid_embed_vectors.append(evid_embeds[i][1])\n","        \n","          if (i+1) % BATCH_SIZE == 0:\n","            evid_embed_vectors = torch.Tensor(evid_embed_vectors)\n","            evid_embed_vectors = evid_embed_vectors.cuda(gpu)\n","\n","            predict = net.neural_layer(test_embed_vector, evid_embed_vectors, BATCH_SIZE).tolist()\n","\n","            for j in range(BATCH_SIZE):\n","              tmp_evid.append((ids[j], predict[j][0]))\n","\n","            ids = []\n","            evid_embed_vectors = []\n","        \n","\n","      tmp_evid.sort(reverse=True, key = lambda x:x[1])\n","      top_5_test_evid[test_id] = tmp_evid[:5]\n","\n","  with open('./drive/My Drive/LAB/COMP90042 A3/predictions/Retrieval_BERT_test.pickle', 'wb') as f:\n","    pickle.dump(top_5_test_evid, f)\n","  \n","  processed_test_embed.append(evid_embed_dir)\n","  with open('./drive/My Drive/LAB/COMP90042 A3/embeddings/processed_test_embed.json', 'w') as f:\n","    json.dump(processed_test_embed, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683603559637,"user":{"displayName":"Chen Zeping","userId":"02749148959880454940"},"user_tz":-600},"id":"0_OGsufNlWQm","outputId":"70e452cb-7085-4dd3-f619-cbf896a1860e"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["BATCH_SIZE = 1024\n","\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PqfXCtBXlGuY"},"outputs":[],"source":["top_5_future_evid = {}\n","processed_future_embed = []"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1132303,"status":"ok","timestamp":1683618293179,"user":{"displayName":"Chen Zeping","userId":"02749148959880454940"},"user_tz":-600},"id":"FWdte5Q9kxpN","outputId":"e27f935d-63a1-4ae3-86cb-afd5b724016a"},"outputs":[{"name":"stdout","output_type":"stream","text":["pass evid_embed6400.json\n","evid_embed12800.json\n","evid_embed19200.json\n","evid_embed25600.json\n","evid_embed32000.json\n","evid_embed38400.json\n","evid_embed44800.json\n","evid_embed51200.json\n","evid_embed57600.json\n","evid_embed64000.json\n","evid_embed70400.json\n","evid_embed76800.json\n","evid_embed83200.json\n","evid_embed89600.json\n","evid_embed96000.json\n","evid_embed102400.json\n","evid_embed108800.json\n","evid_embed115200.json\n","evid_embed121600.json\n","evid_embed128000.json\n","evid_embed134400.json\n","evid_embed140800.json\n","evid_embed147200.json\n","evid_embed153600.json\n","evid_embed160000.json\n","evid_embed166400.json\n","evid_embed172800.json\n","evid_embed179200.json\n","evid_embed185600.json\n","evid_embed192000.json\n","evid_embed198400.json\n","evid_embed204800.json\n","evid_embed211200.json\n","evid_embed217600.json\n","evid_embed224000.json\n","evid_embed230400.json\n","evid_embed236800.json\n","evid_embed243200.json\n","evid_embed249600.json\n","evid_embed256000.json\n","evid_embed262400.json\n","evid_embed268800.json\n","evid_embed275200.json\n","evid_embed281600.json\n","evid_embed288000.json\n","evid_embed294400.json\n","evid_embed300800.json\n","evid_embed302207.json\n"]}],"source":["for evid_embed_dir in evid_embed_list:\n","\n","  if evid_embed_dir in processed_future_embed:\n","    print('pass', evid_embed_dir)\n","    continue\n","  \n","  print(evid_embed_dir)\n","  \n","  with open(f'./drive/My Drive/LAB/COMP90042 A3/embeddings/evid_embedding/{evid_embed_dir}', 'r') as f:\n","    evid_embed = json.load(f)\n","    evid_embeds = [(evid_id, evid_embed[evid_id]) for evid_id in evid_embed]\n","\n","    for future_id in future_embed:\n","\n","      future_embed_vector = torch.Tensor([future_embed[future_id] for i in range(BATCH_SIZE)])\n","      future_embed_vector = future_embed_vector.cuda(gpu)\n","      \n","      if future_id in top_5_future_evid:\n","        tmp_evid = copy.deepcopy(top_5_future_evid[future_id])\n","      else:\n","        tmp_evid = []\n","\n","      with torch.no_grad():\n","        ids = []\n","        evid_embed_vectors = []\n","        for i in range(len(evid_embeds)):\n","          ids.append(evid_embeds[i][0])\n","          evid_embed_vectors.append(evid_embeds[i][1])\n","        \n","          if (i+1) % BATCH_SIZE == 0:\n","            evid_embed_vectors = torch.Tensor(evid_embed_vectors)\n","            evid_embed_vectors = evid_embed_vectors.cuda(gpu)\n","\n","            predict = net.neural_layer(future_embed_vector, evid_embed_vectors, BATCH_SIZE).tolist()\n","\n","            for j in range(BATCH_SIZE):\n","              tmp_evid.append((ids[j], predict[j][0]))\n","\n","            ids = []\n","            evid_embed_vectors = []\n","        \n","\n","      tmp_evid.sort(reverse=True, key = lambda x:x[1])\n","      top_5_future_evid[future_id] = tmp_evid[:5]\n","\n","  with open('./drive/My Drive/LAB/COMP90042 A3/predictions/Retrieval_BERT_future.pickle', 'wb') as f:\n","    pickle.dump(top_5_future_evid, f)\n","  \n","  processed_future_embed.append(evid_embed_dir)\n","  with open('./drive/My Drive/LAB/COMP90042 A3/embeddings/processed_future_embed.pickle', 'wb') as f:\n","    pickle.dump(processed_future_embed, f)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"amXHyPPGLOue"},"source":["F score"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLugJKoDMqbV"},"outputs":[],"source":["class PredictDataset():\n","\n","    def __init__(self, data, maxlen):\n","\n","        #Store the contents of the file in a pandas dataframe\n","        self.data = data\n","\n","        #Initialize the BERT tokenizer\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","        self.maxlen = maxlen\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","\n","        #Selecting the sentence and label at the specified index in the data frame\n","        sentence1 = self.data[index][0][0]\n","        sentence2 = self.data[index][0][1]\n","\n","        #Preprocessing the text to be suitable for BERT\n","        tokens1 = tokenizer.tokenize(sentence1)\n","        tokens2 = tokenizer.tokenize(sentence2)\n","        tokens1 = ['[CLS]'] + tokens1 + ['[SEP]']\n","        tokens2 = ['[CLS]'] + tokens2 + ['[SEP]']\n","        if len(tokens1) < self.maxlen:\n","            tokens1 = tokens1 + ['[PAD]' for _ in range(self.maxlen - len(tokens1))] #Padding sentences\n","        else:\n","            tokens1 = tokens1[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n","\n","        if len(tokens2) < self.maxlen:\n","            tokens2 = tokens2 + ['[PAD]' for _ in range(self.maxlen - len(tokens2))] #Padding sentences\n","        else:\n","            tokens2 = tokens2[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n","\n","        tokens_ids1 = self.tokenizer.convert_tokens_to_ids(tokens1) #Obtaining the indices of the tokens in the BERT Vocabulary\n","        tokens_ids_tensor1 = torch.tensor(tokens_ids1) #Converting the list to a pytorch tensor\n","\n","        tokens_ids2 = self.tokenizer.convert_tokens_to_ids(tokens2) #Obtaining the indices of the tokens in the BERT Vocabulary\n","        tokens_ids_tensor2 = torch.tensor(tokens_ids2) #Converting the list to a pytorch tensor\n","\n","        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n","        attn_mask1 = (tokens_ids_tensor1 != 0).long()\n","        attn_mask2 = (tokens_ids_tensor2 != 0).long()\n","\n","\n","\n","        return tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1683379452404,"user":{"displayName":"Lang Chen","userId":"02743582657302157093"},"user_tz":-600},"id":"C5cl5ufaBXUf","outputId":"a7311270-94c4-40c4-e39a-2411cf79e165"},"outputs":[{"data":{"text/plain":["9"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U9qPoCOh_x-7"},"outputs":[],"source":["EVIDENCE = [(claim,evidence[claim]) for claim in scientific_claims_id]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPuflekhLI1c"},"outputs":[],"source":["def get_retrievals(claims, file_name, SIZE=32):\n","  try:\n","    with open(f'./drive/My Drive/LAB/COMP90042 A3/predictions/Retrievals/{file_name}.pickle', 'rb') as f:\n","      retrievals = pickle.load(f)\n","  except:\n","      retrievals = {}\n","\n","  EVIDENCE.sort(key = lambda x:x[0])\n","\n","  i = 0\n","  for id in claims:\n","    if id in retrievals:\n","      print('pass:', id)\n","      continue\n","\n","    print(id)\n","    data_for_predict = []\n","\n","    claim_text = claims[id]['claim_text']\n","\n","    for evid in EVIDENCE:\n","\n","      evid_text = evid[1]\n","\n","      data_for_predict.append((claim_text, evid_text))\n","\n","    set_for_predict = PredictDataset(data_for_predict, maxlen = 512)\n","\n","    predict_loader = DataLoader(set_for_predict, batch_size = SIZE, num_workers = 2)\n","    \n","    predicted_logit = list()\n","    with torch.no_grad():\n","      for it, (tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2) in enumerate(predict_loader):\n","        \n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2 = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu), tokens_ids_tensor2.cuda(gpu), attn_mask2.cuda(gpu)\n","\n","        logits = net(tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2).tolist()\n","        logits = [x[0] for x in logits]\n","        \n","        for prediction in zip([claim_id for claim_id in EVIDENCE[it*SIZE:(it+1)*SIZE+1]], logits):\n","          predicted_logit.append(prediction)\n","      \n","      predicted_logit.sort(key = lambda x:x[1], reverse = True)\n","      predicted_logit = predicted_logit[:5]\n","\n","      retrievals[id] = {'evidences': [x[0] for x in predicted_logit]}\n","\n","      with open(f'./drive/My Drive/LAB/COMP90042 A3/predictions/Retrievals/{file_name}.pickle', 'wb') as f:\n","          pickle.dump(retrievals, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjA24LYuMf0w","outputId":"c7cfe9a7-ce51-4b37-fb58-6ae9cdd17c34"},"outputs":[{"name":"stdout","output_type":"stream","text":["pass: claim-752\n","pass: claim-375\n","pass: claim-1266\n","pass: claim-871\n","pass: claim-2164\n","pass: claim-1607\n","pass: claim-761\n","pass: claim-1718\n","pass: claim-1273\n","pass: claim-1786\n","pass: claim-2796\n","pass: claim-2580\n","pass: claim-1219\n","pass: claim-75\n","pass: claim-2813\n","pass: claim-2335\n","pass: claim-161\n","pass: claim-2243\n","pass: claim-1256\n","pass: claim-506\n","pass: claim-369\n","pass: claim-2184\n","pass: claim-1057\n","pass: claim-104\n","pass: claim-1975\n","pass: claim-139\n","pass: claim-2062\n","pass: claim-1160\n","pass: claim-2679\n","pass: claim-2662\n","pass: claim-1490\n","pass: claim-2768\n","pass: claim-2168\n","pass: claim-785\n","pass: claim-2426\n","pass: claim-1292\n","pass: claim-993\n","pass: claim-2593\n","pass: claim-1567\n","pass: claim-1834\n","pass: claim-856\n","pass: claim-540\n","pass: claim-757\n","pass: claim-1407\n","pass: claim-3070\n","pass: claim-1745\n","pass: claim-1515\n","pass: claim-1519\n","pass: claim-3069\n","pass: claim-677\n","pass: claim-765\n","pass: claim-2275\n","pass: claim-1113\n","pass: claim-2611\n","pass: claim-2060\n","pass: claim-2326\n","pass: claim-1087\n","pass: claim-2867\n","pass: claim-2300\n","pass: claim-2250\n","pass: claim-2429\n","pass: claim-3051\n","pass: claim-1549\n","pass: claim-261\n","pass: claim-2230\n","pass: claim-2579\n","pass: claim-1416\n","pass: claim-2497\n","pass: claim-811\n","pass: claim-1896\n","pass: claim-2819\n","pass: claim-2643\n","pass: claim-1775\n","pass: claim-316\n","pass: claim-896\n","pass: claim-331\n","pass: claim-2574\n","pass: claim-342\n","pass: claim-2034\n","pass: claim-578\n","pass: claim-976\n","pass: claim-1097\n","pass: claim-609\n","pass: claim-173\n","pass: claim-1222\n","pass: claim-2441\n","pass: claim-756\n","pass: claim-2577\n","pass: claim-2890\n","pass: claim-2478\n","pass: claim-2399\n","pass: claim-3091\n","pass: claim-141\n","pass: claim-1933\n","pass: claim-1689\n","pass: claim-443\n","pass: claim-2037\n","pass: claim-1734\n","pass: claim-2093\n","pass: claim-1400\n","pass: claim-1638\n","pass: claim-3075\n","pass: claim-38\n","pass: claim-1643\n","pass: claim-1259\n","pass: claim-1605\n","pass: claim-1711\n","pass: claim-2236\n","pass: claim-1040\n","pass: claim-392\n","pass: claim-368\n","pass: claim-559\n","pass: claim-2583\n","pass: claim-2609\n","pass: claim-492\n","pass: claim-1420\n","pass: claim-1089\n","pass: claim-1467\n","pass: claim-444\n","pass: claim-803\n","pass: claim-1668\n","pass: claim-742\n","pass: claim-846\n","claim-2119\n","claim-1167\n","claim-623\n","claim-2882\n","claim-1698\n","claim-181\n","claim-281\n","claim-2809\n","claim-1928\n","claim-2787\n","claim-478\n","claim-988\n","claim-266\n","claim-2282\n","claim-2895\n","claim-349\n","claim-2101\n"]}],"source":["get_retrievals(dev_claims, 'Retrieval_SBERT_reduced_dev', SIZE=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsoiYxAGMqvc"},"outputs":[],"source":["get_retrievals(test_claims, 'Retrieval_SBERT_reduced_test', SIZE=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":235953,"status":"error","timestamp":1683379689378,"user":{"displayName":"Lang Chen","userId":"02743582657302157093"},"user_tz":-600},"id":"eIZfSYjEMj6u","outputId":"d2ac5040-443c-4587-f249-8f30924b2ea3"},"outputs":[{"name":"stdout","output_type":"stream","text":["pass: claim-2967\n","pass: claim-979\n","pass: claim-1609\n","pass: claim-1020\n","pass: claim-2599\n","pass: claim-2110\n","pass: claim-1135\n","pass: claim-712\n","pass: claim-1307\n","pass: claim-148\n","pass: claim-903\n","pass: claim-2942\n","pass: claim-1001\n","pass: claim-1034\n","pass: claim-1009\n","pass: claim-770\n","pass: claim-3074\n","pass: claim-1761\n","pass: claim-1475\n","pass: claim-477\n","pass: claim-1378\n","pass: claim-503\n","pass: claim-2751\n","pass: claim-2575\n","pass: claim-30\n","pass: claim-2994\n","pass: claim-55\n","pass: claim-1271\n","pass: claim-2248\n","pass: claim-532\n","pass: claim-556\n","pass: claim-1173\n","pass: claim-539\n","pass: claim-893\n","pass: claim-2857\n","pass: claim-109\n","pass: claim-2476\n","pass: claim-3038\n","pass: claim-3127\n","pass: claim-474\n","pass: claim-2464\n","pass: claim-2427\n","pass: claim-2167\n","pass: claim-812\n","pass: claim-2590\n","pass: claim-404\n","pass: claim-2977\n","pass: claim-2673\n","pass: claim-2509\n","pass: claim-138\n","pass: claim-952\n","pass: claim-1691\n","pass: claim-1741\n","pass: claim-1202\n","pass: claim-1028\n","pass: claim-28\n","pass: claim-275\n","pass: claim-350\n","pass: claim-2204\n","pass: claim-1604\n","pass: claim-3119\n","pass: claim-2150\n","pass: claim-21\n","pass: claim-2013\n","pass: claim-467\n","pass: claim-2754\n","pass: claim-2797\n","pass: claim-1771\n","pass: claim-1908\n","pass: claim-2000\n","pass: claim-2084\n","pass: claim-1237\n","pass: claim-400\n","pass: claim-1508\n","pass: claim-520\n","pass: claim-3064\n","pass: claim-1588\n","claim-1488\n"]},{"ename":"NameError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-8f55d62629fd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_retrievals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture_claims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Retrieval_SBERT_reduced_future'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-33-fc2310fe3a2e>\u001b[0m in \u001b[0;36mget_retrievals\u001b[0;34m(claims, file_name, SIZE)\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mretrievals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'evidences'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredicted_logit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./drive/My Drive/LAB/COMP90042 A3/predictions/Retrievals/{fiile_name}.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m           \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrievals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'fiile_name' is not defined"]}],"source":["get_retrievals(future_claims, 'Retrieval_SBERT_reduced_future', SIZE=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aY2ic3lINAK8"},"outputs":[],"source":["# with open('./drive/My Drive/LAB/COMP90042 A3/notebooks/test_predictions_sentence.pickle', 'rb') as f:\n","#   final_test_predictions_sentence = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SX-16tDG21DY"},"outputs":[],"source":["# final_test_predictions_sentence = {}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1229161,"status":"ok","timestamp":1683289988999,"user":{"displayName":"Zeping Chen","userId":"17844763960576389588"},"user_tz":-600},"id":"qNCjJgL9M_Te","outputId":"848c3d97-8a41-4bfa-ed44-509624fd201a"},"outputs":[{"name":"stdout","output_type":"stream","text":["pass: claim-1898\n","pass: claim-2276\n","pass: claim-564\n","pass: claim-3003\n","pass: claim-2173\n","pass: claim-1818\n","pass: claim-2903\n","pass: claim-1362\n","pass: claim-2726\n","pass: claim-1466\n","pass: claim-2040\n","pass: claim-311\n","pass: claim-1855\n","pass: claim-72\n","pass: claim-840\n","pass: claim-1075\n","pass: claim-2374\n","pass: claim-2305\n","pass: claim-904\n","pass: claim-1276\n","pass: claim-447\n","pass: claim-1673\n","pass: claim-2181\n","pass: claim-1360\n","pass: claim-2901\n","pass: claim-586\n","pass: claim-788\n","pass: claim-3009\n","pass: claim-2837\n","pass: claim-1553\n","pass: claim-1649\n","pass: claim-2682\n","pass: claim-1719\n","pass: claim-787\n","pass: claim-2430\n","pass: claim-3062\n","pass: claim-1286\n","pass: claim-1465\n","pass: claim-1067\n","pass: claim-2745\n","pass: claim-2720\n","pass: claim-2032\n","pass: claim-1991\n","pass: claim-920\n","pass: claim-1421\n","pass: claim-1555\n","pass: claim-2358\n","pass: claim-1565\n","pass: claim-582\n","pass: claim-1399\n","pass: claim-555\n","pass: claim-1923\n","pass: claim-1658\n","pass: claim-512\n","pass: claim-248\n","pass: claim-1980\n","pass: claim-1492\n","pass: claim-948\n","pass: claim-2912\n","pass: claim-2004\n","pass: claim-1717\n","pass: claim-995\n","pass: claim-3079\n","pass: claim-2068\n","claim-1817\n","pass: claim-2223\n","claim-1825\n","pass: claim-2009\n","claim-2542\n","pass: claim-508\n","claim-189\n","pass: claim-44\n","claim-1376\n","pass: claim-939\n","claim-1357\n","pass: claim-849\n","claim-418\n","pass: claim-2272\n","claim-1983\n","pass: claim-1504\n","pass: claim-1626\n","pass: claim-1510\n","pass: claim-1463\n","pass: claim-666\n","pass: claim-1434\n","pass: claim-2694\n","pass: claim-1678\n","pass: claim-1462\n","pass: claim-1871\n","pass: claim-2312\n","pass: claim-337\n","pass: claim-2214\n","pass: claim-962\n","pass: claim-434\n","pass: claim-2827\n","pass: claim-1049\n","pass: claim-1369\n","pass: claim-728\n","pass: claim-1875\n","pass: claim-1819\n","pass: claim-378\n","pass: claim-1623\n","pass: claim-1270\n","pass: claim-3000\n","pass: claim-1495\n","pass: claim-2834\n","pass: claim-807\n","pass: claim-1932\n","pass: claim-2916\n","pass: claim-1151\n","pass: claim-169\n","pass: claim-1592\n","pass: claim-442\n","pass: claim-590\n","pass: claim-1178\n","pass: claim-1406\n","pass: claim-1874\n","pass: claim-1562\n","pass: claim-6\n","pass: claim-2522\n","pass: claim-1793\n","pass: claim-2457\n","pass: claim-2049\n","pass: claim-1971\n","pass: claim-2712\n","pass: claim-3130\n","pass: claim-800\n","pass: claim-399\n","pass: claim-2290\n","pass: claim-2047\n","pass: claim-1150\n","pass: claim-198\n","pass: claim-1524\n","pass: claim-246\n","pass: claim-3008\n","pass: claim-412\n","pass: claim-2641\n","pass: claim-2365\n","pass: claim-388\n","pass: claim-2229\n","pass: claim-3099\n","pass: claim-1703\n","pass: claim-3066\n","pass: claim-1831\n","pass: claim-1142\n","pass: claim-863\n","pass: claim-1389\n","pass: claim-2565\n","pass: claim-100\n","pass: claim-2390\n","claim-676\n","pass: claim-2320\n","claim-2387\n","pass: claim-2612\n"]}],"source":["# SIZE = 32\n","\n","# EVIDENCE.sort(key = lambda x:x[0])\n","\n","# i = 0\n","# for id in test_claims:\n","#   if id in final_test_predictions_sentence:\n","#     print('pass:', id)\n","#     continue\n","\n","#   print(id)\n","#   test_data_for_predict = []\n","\n","#   claim_text = test_claims[id]['claim_text']\n","\n","#   for evid in EVIDENCE:\n","\n","#     evid_text = evid[1]\n","\n","#     test_data_for_predict.append((claim_text, evid_text))\n","\n","#   test_set_for_predict = PredictDataset(test_data_for_predict, maxlen = 512)\n","\n","#   test_predict_loader = DataLoader(test_set_for_predict, batch_size = SIZE, num_workers = 2)\n","  \n","#   predicted_logit = list()\n","#   with torch.no_grad():\n","#     for it, (tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2) in enumerate(dev_predict_loader):\n","      \n","#       torch.cuda.empty_cache()\n","#       gc.collect()\n","#       tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2 = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu), tokens_ids_tensor2.cuda(gpu), attn_mask2.cuda(gpu)\n","\n","#       logits = net(tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2).tolist()\n","#       logits = [x[0] for x in logits]\n","      \n","#       for prediction in zip([claim_id for claim_id in EVIDENCE[it*SIZE:(it+1)*SIZE+1]], logits):\n","#         predicted_logit.append(prediction)\n","    \n","#     predicted_logit.sort(key = lambda x:x[1], reverse = True)\n","#     predicted_logit = predicted_logit[:5]\n","\n","#     final_test_predictions_sentence[id] = {'evidences': [x[0] for x in predicted_logit]}\n","\n","#     with open('./drive/My Drive/LAB/COMP90042 A3/notebooks/test_predictions_sentence.pickle', 'wb') as f:\n","#         pickle.dump(final_test_predictions_sentence, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K78bBI8JAUTT"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0b0b2b1ac0554e06958a5b8e77d3b784":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"234cfe7030464869b7696b5166c1482f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2964054e70244d55a1185ae0288024ba":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d731007bf9e4ace80b12b1654b69b70":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f754c36328e469ba390d7dc51e55391":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33f3e88a90d24832b79279fa2cec02d3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_daa34368dc314890b53d9d91039378fe","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60cc7066aa324e789034d3146755855f","value":570}},"54038c5f53ed4fc2baccaf3978458b10":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"544c3deb8b6e4a52b00942eb2e0d7671":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8ee15200b3842818a3fdaa3e713adbd","placeholder":"​","style":"IPY_MODEL_234cfe7030464869b7696b5166c1482f","value":" 28.0/28.0 [00:00&lt;00:00, 1.89kB/s]"}},"56cf6a10e1f34fd892667e26cdaf8a40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"58f690aaf6a24b8f9cffd44209a6f06d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d731007bf9e4ace80b12b1654b69b70","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4e05c6a162a4da39a8e78604401669f","value":28}},"5b18df5a30b94c08bdae9d4ef44d8ebe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54038c5f53ed4fc2baccaf3978458b10","placeholder":"​","style":"IPY_MODEL_f6186618276d41d6a5f1949396f2f063","value":" 570/570 [00:00&lt;00:00, 29.1kB/s]"}},"60cc7066aa324e789034d3146755855f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"61da5e0d42004741a05a54368aa5bf62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64e18086a8ba433c934c6380e7e57369":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"76b26c4a47b84d999df10a93c0c19353":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61da5e0d42004741a05a54368aa5bf62","placeholder":"​","style":"IPY_MODEL_64e18086a8ba433c934c6380e7e57369","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"7d146490eb864ee5a445820bf5ebb06b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d95a0e580834f85b32f5e7134973f23":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5407f4b1b1a43008cba346c7425c44f","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f754c36328e469ba390d7dc51e55391","value":440473133}},"82d122bbeb5c447ab07efabba6324b58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84f2bc4362c3435b9ec93223cd0ce3bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_870be3722d8e4f65bc06609b682ead62","placeholder":"​","style":"IPY_MODEL_f4da26461d544aefacf7718f7ba1b118","value":" 232k/232k [00:00&lt;00:00, 8.18MB/s]"}},"870be3722d8e4f65bc06609b682ead62":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"871eb0a67a20437eb22f5fb68697a60e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_76b26c4a47b84d999df10a93c0c19353","IPY_MODEL_db9877b7918547dc8cf4f2f84962c709","IPY_MODEL_84f2bc4362c3435b9ec93223cd0ce3bf"],"layout":"IPY_MODEL_b9f3ec75d92c48d5b91c40fe263c71d1"}},"8ff3fdcfa54542578b298d5fb9a4038a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5c70a64dc1047b2b79a451cd7b0733c","placeholder":"​","style":"IPY_MODEL_82d122bbeb5c447ab07efabba6324b58","value":" 440M/440M [00:27&lt;00:00, 16.2MB/s]"}},"926278e7b5474fe88d14d54f9ce269ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"960c0e13f8eb436bae66c1380cd57d64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ced6bf3c6524fcaaec3057e189b3a75":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc608abba2ce46889cdef4353437e729","IPY_MODEL_58f690aaf6a24b8f9cffd44209a6f06d","IPY_MODEL_544c3deb8b6e4a52b00942eb2e0d7671"],"layout":"IPY_MODEL_e0a2b5c2e31a4c22a1aaa0bdf41aeca3"}},"a4e05c6a162a4da39a8e78604401669f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a5407f4b1b1a43008cba346c7425c44f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5c70a64dc1047b2b79a451cd7b0733c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac67650483254d4480dc9ce1561306ec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b18cdacecef340bbb9af72a89bede5e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_926278e7b5474fe88d14d54f9ce269ab","placeholder":"​","style":"IPY_MODEL_0b0b2b1ac0554e06958a5b8e77d3b784","value":"Downloading (…)lve/main/config.json: 100%"}},"b8ee15200b3842818a3fdaa3e713adbd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9f3ec75d92c48d5b91c40fe263c71d1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be2faa9c24134b8291a39dccd5fb533e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b18cdacecef340bbb9af72a89bede5e1","IPY_MODEL_33f3e88a90d24832b79279fa2cec02d3","IPY_MODEL_5b18df5a30b94c08bdae9d4ef44d8ebe"],"layout":"IPY_MODEL_fde1c86393794e9f81e8dc077596df25"}},"c0e55de10cfb41339625a4f4aa136def":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d146490eb864ee5a445820bf5ebb06b","placeholder":"​","style":"IPY_MODEL_56cf6a10e1f34fd892667e26cdaf8a40","value":"Downloading pytorch_model.bin: 100%"}},"daa34368dc314890b53d9d91039378fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db9877b7918547dc8cf4f2f84962c709":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac67650483254d4480dc9ce1561306ec","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_960c0e13f8eb436bae66c1380cd57d64","value":231508}},"e0a2b5c2e31a4c22a1aaa0bdf41aeca3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8ef2735a9464883a5ea748e26f610be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0e55de10cfb41339625a4f4aa136def","IPY_MODEL_7d95a0e580834f85b32f5e7134973f23","IPY_MODEL_8ff3fdcfa54542578b298d5fb9a4038a"],"layout":"IPY_MODEL_e955ffd79a9a4b8da9d532dfebbe0d48"}},"e955ffd79a9a4b8da9d532dfebbe0d48":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4da26461d544aefacf7718f7ba1b118":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6186618276d41d6a5f1949396f2f063":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f8c4c7f2cc214037aabd6ce10654991e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc608abba2ce46889cdef4353437e729":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2964054e70244d55a1185ae0288024ba","placeholder":"​","style":"IPY_MODEL_f8c4c7f2cc214037aabd6ce10654991e","value":"Downloading (…)okenizer_config.json: 100%"}},"fde1c86393794e9f81e8dc077596df25":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
