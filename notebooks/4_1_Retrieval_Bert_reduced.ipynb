{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 4.1 Retrieval BERT - reduced"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30319,"status":"ok","timestamp":1683345081824,"user":{"displayName":"Lang Chen","userId":"16809580542675905601"},"user_tz":-600},"id":"pBV7EEw8ws--","outputId":"b07343e3-a323-4860-e127-f9323f69b25d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Read in Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvlHUjGBxi6U"},"outputs":[],"source":["import json\n","import numpy as np\n","import gc\n","import pickle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SxJxwC3uxAHJ"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/curated/train_claims2.json') as f:\n","    train_claims = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WnJs6bPCxdS-"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/raw/dev-claims.json') as f:\n","    dev_claims = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIERH2G4LB2S"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/curated/test_claims2.json') as f:\n","    test_claims = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjY4K8Xn82mJ"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/raw/test-claims-unlabelled.json') as f:\n","    future_claims = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3gJUbs3YxsS2"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/raw/evidence.json') as f:\n","    evidence = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qu3MUOzgzok0"},"outputs":[],"source":["import random\n","random.seed(19260817)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Reduce claims"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MgeHLHmOsyJ6"},"outputs":[],"source":["scientific_claims_id = set()\n","for claim in train_claims:\n","  for evid in train_claims[claim]['evidences']:\n","    scientific_claims_id.add(evid)\n","\n","for claim in dev_claims:\n","  for evid in dev_claims[claim]['evidences']:\n","    scientific_claims_id.add(evid)\n","\n","for claim in test_claims:\n","  for evid in test_claims[claim]['evidences']:\n","    scientific_claims_id.add(evid)\n","\n","\n","scientific_claims_id = list(scientific_claims_id)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Create dataset used to train retriever"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aC_RdtG1tbmA"},"outputs":[],"source":["NEG_SAMPLE_FACTOR = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6aGfiIv-ynQ3"},"outputs":[],"source":["training_data = []\n","\n","for id in train_claims:\n","\n","  claim_text = train_claims[id]['claim_text']\n","\n","  n_evid = len(train_claims[id]['evidences'])\n","\n","  for evid_id in train_claims[id]['evidences']:\n","    evid_text = evidence[evid_id]\n","\n","    training_data.append((((claim_text, evid_text)), 1))\n","  \n","  #negative sampling\n","  neg_sampled = 0\n","  while neg_sampled < n_evid * NEG_SAMPLE_FACTOR:\n","    sampled_neg_evid_id = random.choice(scientific_claims_id)\n","    if sampled_neg_evid_id not in train_claims[id]['evidences']:\n","      neg_sampled += 1\n","      evid_text = evidence[sampled_neg_evid_id]\n","\n","      training_data.append((((claim_text, evid_text)), 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjkog1CQz8IN"},"outputs":[],"source":["dev_data = []\n","\n","for id in dev_claims:\n","\n","  claim_text = dev_claims[id]['claim_text']\n","\n","  n_evid = len(dev_claims[id]['evidences'])\n","\n","  for evid_id in dev_claims[id]['evidences']:\n","    evid_text = evidence[evid_id]\n","\n","    dev_data.append((((claim_text, evid_text)), 1))\n","  \n","  #negative sampling\n","  neg_sampled = 0\n","  while neg_sampled < n_evid * NEG_SAMPLE_FACTOR:\n","    sampled_neg_evid_id = random.choice(scientific_claims_id)\n","    if sampled_neg_evid_id not in dev_claims[id]['evidences']:\n","      neg_sampled += 1\n","      evid_text = evidence[sampled_neg_evid_id]\n","\n","      dev_data.append((((claim_text, evid_text)), 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mYCdTk7kK7jr"},"outputs":[],"source":["test_data = []\n","\n","for id in test_claims:\n","\n","  claim_text = test_claims[id]['claim_text']\n","\n","  n_evid = len(test_claims[id]['evidences'])\n","\n","  for evid_id in test_claims[id]['evidences']:\n","    evid_text = evidence[evid_id]\n","\n","    test_data.append((((claim_text, evid_text)), 1))\n","  \n","  #negative sampling\n","  neg_sampled = 0\n","  while neg_sampled < n_evid * NEG_SAMPLE_FACTOR:\n","    sampled_neg_evid_id = random.choice(scientific_claims_id)\n","    if sampled_neg_evid_id not in test_claims[id]['evidences']:\n","      neg_sampled += 1\n","      evid_text = evidence[sampled_neg_evid_id]\n","\n","      test_data.append((((claim_text, evid_text)), 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12717,"status":"ok","timestamp":1683345103552,"user":{"displayName":"Lang Chen","userId":"16809580542675905601"},"user_tz":-600},"id":"BA0eew_Zxs0O","outputId":"d13109ff-ab6f-4631-feb2-b6e0786b7203"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.2)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m106.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["!pip install torch torchvision transformers"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Build model, dataloader etc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ACUDqscx48V"},"outputs":[],"source":["from transformers import BertModel"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuIdphoS21tC"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from transformers import BertTokenizer\n","import pandas as pd\n","\n","class Dataset():\n","\n","    def __init__(self, data, maxlen):\n","\n","        #Store the contents of the file in a pandas dataframe\n","        self.data = data\n","\n","        #Initialize the BERT tokenizer\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","        self.maxlen = maxlen\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","\n","        #Selecting the sentence and label at the specified index in the data frame\n","        sentence1 = self.data[index][0][0]\n","        sentence2 = self.data[index][0][1]\n","        label = self.data[index][1]\n","\n","        #Preprocessing the text to be suitable for BERT\n","        tokens1 = tokenizer.tokenize(sentence1)\n","        tokens2 = tokenizer.tokenize(sentence2)\n","        tokens1 = ['[CLS]'] + tokens1 + ['[SEP]']\n","        tokens2 = tokens2 + ['[SEP]']\n","        tokens = tokens1 + tokens2 #Insering the CLS and SEP token in the beginning and end of the sentence\n","        if len(tokens) < self.maxlen:\n","            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n","        else:\n","            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n","\n","        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n","        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n","\n","        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n","        attn_mask = (tokens_ids_tensor != 0).long()\n","\n","        seg_ids = [0 for _ in range(len(tokens1))]\n","        seg_ids2 = [1 for _ in range(self.maxlen-len(tokens1))]\n","        seg_ids.extend(seg_ids2)\n","\n","        seg_ids_tensor = torch.tensor(seg_ids)\n","\n","\n","        return tokens_ids_tensor, attn_mask, seg_ids_tensor, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qvOcemHR_bHt"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","#Creating instances of training and development set\n","#maxlen sets the maximum length a sentence can have\n","#any sentence longer than this length is truncated to the maxlen size\n","train_set = Dataset(training_data, maxlen = 512)\n","dev_set = Dataset(dev_data, maxlen = 512)\n","test_set = Dataset(test_data, maxlen = 512)\n","\n","#Creating intsances of training and development dataloaders\n","train_loader = DataLoader(train_set, batch_size = 16, shuffle = True, num_workers = 2)\n","dev_loader = DataLoader(dev_set, batch_size = 16, shuffle = True, num_workers = 2)\n","test_loader = DataLoader(test_set, batch_size = 16, shuffle = True, num_workers = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"srZ-42Pz_oyO"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from transformers import BertModel\n","\n","class RelatednessClassifier(nn.Module):\n","\n","    def __init__(self):\n","        super(RelatednessClassifier, self).__init__()\n","        #Instantiating BERT model object \n","        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n","        \n","        #Classification layer\n","        #input dimension is 768 because [CLS] embedding has a dimension of 768\n","        #output dimension is 1 because we're working with a binary classification problem\n","        self.cls_layer = nn.Linear(768, 1)\n","\n","    def forward(self, seq, attn_masks, seg_ids):\n","        '''\n","        Inputs:\n","            -seq : Tensor of shape [B, T] containing token ids of sequences\n","            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n","        '''\n","\n","        #Feeding the input to BERT model to obtain contextualized representations\n","        outputs = self.bert_layer(seq, attention_mask = attn_masks, token_type_ids = seg_ids, return_dict=True)\n","        cont_reps = outputs.last_hidden_state\n","\n","        #Obtaining the representation of [CLS] head (the first token)\n","        cls_rep = cont_reps[:, 0]\n","\n","        #Feeding cls_rep to the classifier layer\n","        logits = self.cls_layer(cls_rep)\n","\n","        return logits"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":158,"referenced_widgets":["e2822c59b56a4dd68e0864ea87033cb6","f0a62847c8114a8e93c6c2042f43eed1","fd412988e42d4187bf4926da71c5310e","4c531619bdec4ffcbfe1d0474baf63a6","6db593df522c402c96d12dfe2610ff99","55d0c883a0714b8da559c59d803054d8","2c8cba08844d40c88bd87d387fa45fe4","e3de00290b194fb1b97b7259bdf63c1d","834c1206e35a4ce4b0be7a5ed93ef70d","6f125956d00b430c903a9058f86041e8","f1fe0bb7d8f74f2abd094d176848f9bb"]},"executionInfo":{"elapsed":4955,"status":"ok","timestamp":1683345116471,"user":{"displayName":"Lang Chen","userId":"16809580542675905601"},"user_tz":-600},"id":"fA0faPfGAeLl","outputId":"02828e00-db05-4328-f894-021717e77596"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e2822c59b56a4dd68e0864ea87033cb6","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Done creating the sentiment classifier.\n"]}],"source":["gpu = 0 #gpu ID\n","\n","print(\"Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\")\n","net = RelatednessClassifier()\n","net.cuda(gpu) #Enable gpu support for the model\n","print(\"Done creating the sentiment classifier.\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Setup Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CGlc0FwVAlHB"},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","criterion = nn.BCEWithLogitsLoss()\n","opti = optim.Adam(net.parameters(), lr = 2e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L7RR7ohEAnjy"},"outputs":[],"source":["def get_accuracy_from_logits(logits, labels):\n","    probs = torch.sigmoid(logits.unsqueeze(-1))\n","    soft_probs = (probs > 0.5).long()\n","    acc = (soft_probs.squeeze() == labels).float().mean()\n","    return acc\n","\n","def evaluate(net, criterion, dataloader, gpu):\n","    net.eval()\n","\n","    mean_acc, mean_loss = 0, 0\n","    count = 0\n","\n","    with torch.no_grad():\n","        for seq, attn_masks, seg_ids_tensor, labels in dataloader:\n","            seq, attn_masks, seg_ids_tensor, labels = seq.cuda(gpu), attn_masks.cuda(gpu), seg_ids_tensor.cuda(gpu), labels.cuda(gpu)\n","            logits = net(seq, attn_masks, seg_ids_tensor)\n","            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n","            mean_acc += get_accuracy_from_logits(logits, labels)\n","            count += 1\n","\n","    return mean_acc / count, mean_loss / count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eBze9eaUAqLg"},"outputs":[],"source":["import time\n","\n","def train(net, criterion, opti, train_loader, dev_loader, max_eps, gpu):\n","\n","    best_acc = 0\n","    st = time.time()\n","    for ep in range(max_eps):\n","        \n","        net.train()\n","        for it, (seq, attn_masks, seg_ids_tensor, labels) in enumerate(train_loader):\n","            #Clear gradients\n","            opti.zero_grad()  \n","            #Converting these to cuda tensors\n","            seq, attn_masks, seg_ids_tensor, labels = seq.cuda(gpu), attn_masks.cuda(gpu), seg_ids_tensor.cuda(gpu), labels.cuda(gpu)\n","\n","            #Obtaining the logits from the model\n","            logits = net(seq, attn_masks, seg_ids_tensor)\n","\n","            #Computing loss\n","            loss = criterion(logits.squeeze(-1), labels.float())\n","\n","            #Backpropagating the gradients\n","            loss.backward()\n","\n","            #Optimization step\n","            opti.step()\n","              \n","            if it % 100 == 0:\n","                \n","                acc = get_accuracy_from_logits(logits, labels)\n","                print(\"Iteration {} of epoch {} complete. Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n","                st = time.time()\n","\n","        \n","        dev_acc, dev_loss = evaluate(net, criterion, dev_loader, gpu)\n","        print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(ep, dev_acc, dev_loss))\n","        if dev_acc > best_acc:\n","            print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n","            best_acc = dev_acc\n","            torch.save(net.state_dict(), './drive/My Drive/LAB/COMP90042 A3/models/Retrievers/Retriever_Bert_reduced.pt')\n","            torch.save(net, './drive/My Drive/LAB/COMP90042 A3/models/Retrievers/Retriever_Bert_reduced.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5mhGZTSBB2S"},"outputs":[],"source":["num_epoch = 5\n","\n","#fine-tune the model\n","train(net, criterion, opti, train_loader, dev_loader, num_epoch, gpu)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Read In Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12608,"status":"ok","timestamp":1683345129075,"user":{"displayName":"Lang Chen","userId":"16809580542675905601"},"user_tz":-600},"id":"XExrRgJ6r1Uv","outputId":"b01ccf79-4c95-41f8-9d01-0a58e516bb86"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["net.load_state_dict(torch.load('./drive/My Drive/LAB/COMP90042 A3/models/Retrievers/Retriever_Bert_reduced.dat'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lNE4FUvKAor6"},"outputs":[],"source":["net = torch.load('./drive/My Drive/LAB/COMP90042 A3/models/Retrievers/Retriever_Bert_reduced.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1683345129076,"user":{"displayName":"Lang Chen","userId":"16809580542675905601"},"user_tz":-600},"id":"HzjUr6tcAtxL","outputId":"95698d64-cb67-4ec4-cf50-a3adea1e914b"},"outputs":[{"data":{"text/plain":["RelatednessClassifier(\n","  (bert_layer): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (cls_layer): Linear(in_features=768, out_features=1, bias=True)\n",")"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["net.eval()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Make Predictions (to get Retrievals)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sLugJKoDMqbV"},"outputs":[],"source":["class PredictDataset():\n","\n","    def __init__(self, data, maxlen):\n","\n","        #Store the contents of the file in a pandas dataframe\n","        self.data = data\n","\n","        #Initialize the BERT tokenizer\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","        self.maxlen = maxlen\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","\n","        #Selecting the sentence and label at the specified index in the data frame\n","        sentence1 = self.data[index][0]\n","        sentence2 = self.data[index][1]\n","\n","        #Preprocessing the text to be suitable for BERT\n","        tokens1 = tokenizer.tokenize(sentence1)\n","        tokens2 = tokenizer.tokenize(sentence2)\n","        tokens1 = ['[CLS]'] + tokens1 + ['[SEP]']\n","        tokens2 = tokens2 + ['[SEP]']\n","        tokens = tokens1 + tokens2 #Insering the CLS and SEP token in the beginning and end of the sentence\n","        if len(tokens) < self.maxlen:\n","            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n","        else:\n","            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n","\n","        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n","        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n","\n","        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n","        attn_mask = (tokens_ids_tensor != 0).long()\n","\n","        seg_ids = [0 for _ in range(len(tokens1))]\n","        seg_ids2 = [1 for _ in range(self.maxlen-len(tokens1))]\n","        seg_ids.extend(seg_ids2)\n","\n","        seg_ids_tensor = torch.tensor(seg_ids)\n","\n","\n","        return tokens_ids_tensor, attn_mask, seg_ids_tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1683345129076,"user":{"displayName":"Lang Chen","userId":"16809580542675905601"},"user_tz":-600},"id":"C5cl5ufaBXUf","outputId":"6fbf4d0d-8d7b-43a0-99d0-4601201f6cf9"},"outputs":[{"data":{"text/plain":["21"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["EVIDENCE = [(claim,evidence[claim]) for claim in scientific_claims_id]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lPuflekhLI1c"},"outputs":[],"source":["def get_retrievals(claims, file_name, SIZE=32):\n","  try:\n","    with open(f'./drive/My Drive/LAB/COMP90042 A3/predictions/Retrievals/{file_name}.pickle', 'rb') as f:\n","      retrievals = pickle.load(f)\n","  except:\n","      retrievals = {}\n","\n","  EVIDENCE.sort(key = lambda x:x[0])\n","\n","  i = 0\n","  for id in claims:\n","    if id in retrievals:\n","      print('pass:', id)\n","      continue\n","\n","    print(id)\n","    data_for_predict = []\n","\n","    claim_text = claims[id]['claim_text']\n","\n","    for evid in EVIDENCE:\n","\n","      evid_text = evid[1]\n","\n","      data_for_predict.append((claim_text, evid_text))\n","\n","    set_for_predict = PredictDataset(data_for_predict, maxlen = 512)\n","\n","    predict_loader = DataLoader(set_for_predict, batch_size = SIZE, num_workers = 2)\n","    \n","    predicted_logit = list()\n","    with torch.no_grad():\n","      for it, (tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2) in enumerate(predict_loader):\n","        \n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2 = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu), tokens_ids_tensor2.cuda(gpu), attn_mask2.cuda(gpu)\n","\n","        logits = net(tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2).tolist()\n","        logits = [x[0] for x in logits]\n","        \n","        for prediction in zip([claim_id for claim_id in EVIDENCE[it*SIZE:(it+1)*SIZE+1]], logits):\n","          predicted_logit.append(prediction)\n","      \n","      predicted_logit.sort(key = lambda x:x[1], reverse = True)\n","      predicted_logit = predicted_logit[:5]\n","\n","      retrievals[id] = {'evidences': [x[0] for x in predicted_logit]}\n","\n","      with open(f'./drive/My Drive/LAB/COMP90042 A3/predictions/Retrievals/{file_name}.pickle', 'wb') as f:\n","          pickle.dump(retrievals, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LjA24LYuMf0w"},"outputs":[],"source":["get_retrievals(dev_claims, 'Retrieval_BERT_reduced_dev', SIZE=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NsoiYxAGMqvc"},"outputs":[],"source":["get_retrievals(test_claims, 'Retrieval_BERT_reduced_test', SIZE=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eIZfSYjEMj6u"},"outputs":[],"source":["get_retrievals(future_claims, 'Retrieval_BERT_reduced_future', SIZE=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K78bBI8JAUTT"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"08a3e2f039a544238556ee956f58c5aa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_60c959486d5f41849e33a2a93d29915f","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a2522074fff4c429910109f6ab3cb1c","value":570}},"0c6566c3f2e240dca17e35baba9c3d12":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d1e0c0e14c74a64a367fec7fdb3a0c1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1e6ab451cc4c423db007e162b9824c03":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67c4638601f94b0a9c6dc6cc0a210f0b","placeholder":"​","style":"IPY_MODEL_b53b9b259e804dfdaca1ef34bc34f7d9","value":"Downloading (…)lve/main/config.json: 100%"}},"27775c42b82d45b880c85247f3ed0f30":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a1f9b24c1874cfdb6fb5fd23973608d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae13257b57eb468696202321ec4bc52b","placeholder":"​","style":"IPY_MODEL_766a5761eb244825a3bb9f8c137cce4c","value":"Downloading (…)okenizer_config.json: 100%"}},"2c8cba08844d40c88bd87d387fa45fe4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"352eb6e03a5f4ed89560e7d7c8a60657":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42819f2389464679bb21adc845b21ad7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1e6ab451cc4c423db007e162b9824c03","IPY_MODEL_08a3e2f039a544238556ee956f58c5aa","IPY_MODEL_b4e5e7e4cab84ee0896639e69b99006b"],"layout":"IPY_MODEL_0c6566c3f2e240dca17e35baba9c3d12"}},"4c531619bdec4ffcbfe1d0474baf63a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6f125956d00b430c903a9058f86041e8","placeholder":"​","style":"IPY_MODEL_f1fe0bb7d8f74f2abd094d176848f9bb","value":" 440M/440M [00:01&lt;00:00, 324MB/s]"}},"51c308dcb6844083b18ac34c00f48082":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c8c04f85be24521945bcf8dd4fdbba0","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8d9e07ab4794f04b82a6adeec7d1329","value":28}},"55d0c883a0714b8da559c59d803054d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bec2ca50f5642879b26601041168bb9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c8c04f85be24521945bcf8dd4fdbba0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60c959486d5f41849e33a2a93d29915f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"654777e700df44b0abb73597db9d911c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67c4638601f94b0a9c6dc6cc0a210f0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6db593df522c402c96d12dfe2610ff99":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f125956d00b430c903a9058f86041e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"766a5761eb244825a3bb9f8c137cce4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7836956d62e64949b4633c5ed33d9b68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a2522074fff4c429910109f6ab3cb1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"834c1206e35a4ce4b0be7a5ed93ef70d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c40e34be4b44fc483893d67f95ad150":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_654777e700df44b0abb73597db9d911c","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_352eb6e03a5f4ed89560e7d7c8a60657","value":231508}},"93815d56f21249898ebe1d3f92244211":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb83c73c178f442e93c603f9577a4006","IPY_MODEL_8c40e34be4b44fc483893d67f95ad150","IPY_MODEL_a57d2eabf1fc40eaadcac11770b5ad1b"],"layout":"IPY_MODEL_df08b2566bcd44f9bc7735579ea02b85"}},"9a52177aa52d4c3bb8d09087320a35be":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2a1f9b24c1874cfdb6fb5fd23973608d","IPY_MODEL_51c308dcb6844083b18ac34c00f48082","IPY_MODEL_f15473eb24aa41d4a46932657e95ad1f"],"layout":"IPY_MODEL_5bec2ca50f5642879b26601041168bb9"}},"a57d2eabf1fc40eaadcac11770b5ad1b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d1e0c0e14c74a64a367fec7fdb3a0c1","placeholder":"​","style":"IPY_MODEL_d6efab18985c43f18a567c08b9fc389d","value":" 232k/232k [00:00&lt;00:00, 1.08MB/s]"}},"a8d9e07ab4794f04b82a6adeec7d1329":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae13257b57eb468696202321ec4bc52b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4e5e7e4cab84ee0896639e69b99006b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fceda267ba624714adf0a3a14f287030","placeholder":"​","style":"IPY_MODEL_beb204699d7240f08b15b5f5c22c70f7","value":" 570/570 [00:00&lt;00:00, 22.5kB/s]"}},"b53b9b259e804dfdaca1ef34bc34f7d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"beb204699d7240f08b15b5f5c22c70f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb83c73c178f442e93c603f9577a4006":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27775c42b82d45b880c85247f3ed0f30","placeholder":"​","style":"IPY_MODEL_7836956d62e64949b4633c5ed33d9b68","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"d6efab18985c43f18a567c08b9fc389d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df08b2566bcd44f9bc7735579ea02b85":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2822c59b56a4dd68e0864ea87033cb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f0a62847c8114a8e93c6c2042f43eed1","IPY_MODEL_fd412988e42d4187bf4926da71c5310e","IPY_MODEL_4c531619bdec4ffcbfe1d0474baf63a6"],"layout":"IPY_MODEL_6db593df522c402c96d12dfe2610ff99"}},"e3de00290b194fb1b97b7259bdf63c1d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9b3cc36a1014ef797ac7172825b9cfa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef3e3834634d42eeb66f4482f2b5c086":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0a62847c8114a8e93c6c2042f43eed1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_55d0c883a0714b8da559c59d803054d8","placeholder":"​","style":"IPY_MODEL_2c8cba08844d40c88bd87d387fa45fe4","value":"Downloading pytorch_model.bin: 100%"}},"f15473eb24aa41d4a46932657e95ad1f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9b3cc36a1014ef797ac7172825b9cfa","placeholder":"​","style":"IPY_MODEL_ef3e3834634d42eeb66f4482f2b5c086","value":" 28.0/28.0 [00:00&lt;00:00, 1.06kB/s]"}},"f1fe0bb7d8f74f2abd094d176848f9bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fceda267ba624714adf0a3a14f287030":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd412988e42d4187bf4926da71c5310e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3de00290b194fb1b97b7259bdf63c1d","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_834c1206e35a4ce4b0be7a5ed93ef70d","value":440473133}}}}},"nbformat":4,"nbformat_minor":0}
