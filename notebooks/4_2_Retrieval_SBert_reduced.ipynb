{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 4.2 Retrieval SBERT - reduced"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36909,"status":"ok","timestamp":1683680275065,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"pBV7EEw8ws--","outputId":"74f5af2f-b318-4b03-b3ec-0246b41b842e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Read in Data"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1683680379286,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"IvlHUjGBxi6U"},"outputs":[],"source":["import json\n","import numpy as np\n","import gc\n","import pickle"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":2373,"status":"ok","timestamp":1683680382214,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"SxJxwC3uxAHJ"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/curated/train_claims2.json') as f:\n","    train_claims = json.load(f)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":913,"status":"ok","timestamp":1683680383123,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"WnJs6bPCxdS-"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/raw/dev-claims.json') as f:\n","    dev_claims = json.load(f)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":726,"status":"ok","timestamp":1683680383843,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"yIERH2G4LB2S"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/curated/test_claims2.json') as f:\n","    test_claims = json.load(f)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":902,"status":"ok","timestamp":1683680384732,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"fjY4K8Xn82mJ"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/raw/test-claims-unlabelled.json') as f:\n","    future_claims = json.load(f)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":3483,"status":"ok","timestamp":1683680388200,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"3gJUbs3YxsS2"},"outputs":[],"source":["with open ('./drive/My Drive/LAB/COMP90042 A3/data/raw/evidence.json') as f:\n","    evidence = json.load(f)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1683680388204,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"qu3MUOzgzok0"},"outputs":[],"source":["import random\n","random.seed(19260817)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Reduce claims"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1683680388205,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"MgeHLHmOsyJ6"},"outputs":[],"source":["scientific_claims_id = set()\n","for claim in train_claims:\n","  for evid in train_claims[claim]['evidences']:\n","    scientific_claims_id.add(evid)\n","\n","for claim in dev_claims:\n","  for evid in dev_claims[claim]['evidences']:\n","    scientific_claims_id.add(evid)\n","\n","for claim in test_claims:\n","  for evid in test_claims[claim]['evidences']:\n","    scientific_claims_id.add(evid)\n","\n","\n","scientific_claims_id = list(scientific_claims_id)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Create dataset used to train retriever"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1683680388206,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"aC_RdtG1tbmA"},"outputs":[],"source":["NEG_SAMPLE_FACTOR = 1"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":31,"status":"ok","timestamp":1683680388207,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"6aGfiIv-ynQ3"},"outputs":[],"source":["training_data = []\n","\n","for id in train_claims:\n","\n","  claim_text = train_claims[id]['claim_text']\n","\n","  n_evid = len(train_claims[id]['evidences'])\n","\n","  for evid_id in train_claims[id]['evidences']:\n","    evid_text = evidence[evid_id]\n","\n","    training_data.append((((claim_text, evid_text)), 1))\n","  \n","  #negative sampling\n","  neg_sampled = 0\n","  while neg_sampled < n_evid * NEG_SAMPLE_FACTOR:\n","    sampled_neg_evid_id = random.choice(scientific_claims_id)\n","    if sampled_neg_evid_id not in train_claims[id]['evidences']:\n","      neg_sampled += 1\n","      evid_text = evidence[sampled_neg_evid_id]\n","\n","      training_data.append((((claim_text, evid_text)), 0))"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1683680388207,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"fjkog1CQz8IN"},"outputs":[],"source":["dev_data = []\n","\n","for id in dev_claims:\n","\n","  claim_text = dev_claims[id]['claim_text']\n","\n","  n_evid = len(dev_claims[id]['evidences'])\n","\n","  for evid_id in dev_claims[id]['evidences']:\n","    evid_text = evidence[evid_id]\n","\n","    dev_data.append((((claim_text, evid_text)), 1))\n","  \n","  #negative sampling\n","  neg_sampled = 0\n","  while neg_sampled < n_evid * NEG_SAMPLE_FACTOR:\n","    sampled_neg_evid_id = random.choice(scientific_claims_id)\n","    if sampled_neg_evid_id not in dev_claims[id]['evidences']:\n","      neg_sampled += 1\n","      evid_text = evidence[sampled_neg_evid_id]\n","\n","      dev_data.append((((claim_text, evid_text)), 0))"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1683680388208,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"mYCdTk7kK7jr"},"outputs":[],"source":["test_data = []\n","\n","for id in test_claims:\n","\n","  claim_text = test_claims[id]['claim_text']\n","\n","  n_evid = len(test_claims[id]['evidences'])\n","\n","  for evid_id in test_claims[id]['evidences']:\n","    evid_text = evidence[evid_id]\n","\n","    test_data.append((((claim_text, evid_text)), 1))\n","  \n","  #negative sampling\n","  neg_sampled = 0\n","  while neg_sampled < n_evid * NEG_SAMPLE_FACTOR:\n","    sampled_neg_evid_id = random.choice(scientific_claims_id)\n","    if sampled_neg_evid_id not in test_claims[id]['evidences']:\n","      neg_sampled += 1\n","      evid_text = evidence[sampled_neg_evid_id]\n","\n","      test_data.append((((claim_text, evid_text)), 0))"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13746,"status":"ok","timestamp":1683680401930,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"BA0eew_Zxs0O","outputId":"d5eef884-8abb-49fc-d041-0299191590cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (8.4.0)\n","Collecting huggingface-hub<1.0,>=0.11.0 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["!pip install torch torchvision transformers"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Build model, dataloader etc"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":5236,"status":"ok","timestamp":1683680407160,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"6ACUDqscx48V"},"outputs":[],"source":["from transformers import BertModel"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["19fced259a97455388584029ade8b555","7dc2510ff41447a88c9616fc910c2fcb","c87f6fac4e7f43168f0ed3217b8311e1","d1a2435a3ab141f19c5f75e1b3522a21","614f2d66fd344a25b7b6383980cd7155","66ca21cf60e04146a6e49c54c4d907cd","5cb6355a47564561905cb85d5e2a215d","b91ce17218374baf88dd6151be2646b1","6f2ac7f41df941d09b5fafca7a33fc80","df58528b10d04385a92883565977b3aa","72e836e1b0de4672b9c146115c9e80d2","5ab1d4ee45214cdc97d235d527d2a8f8","092633a12534423188982d34daa01d20","80f46bd96ade485495becef95abb7e1c","b7b254799dcf42abad93ec967c6390ee","512e9c26893c4863a13fc350f300d298","01c3cf98bb4f4caa94c6a436ad8f185b","915bff8ea4fd4fa387abdb9025b24fcb","a124fbb4489646eaa93712527197f296","3d8f28d0299a43ffba66f77ac5af2445","7f2cd69196c54639a70a7291faa87964","7bb1955df5bd4fa488f6db6bd953d7f4","0e526efe0f104f55babf0db5fdb4b777","217ac96d33974f5ea07c8afa8b1206ce","9a8b59aa137742909bca6d6b85d3e0a2","ba4a9ecb04b847c5ba286c65c7c30cef","4f1a4a4e486c457ca70427d16f4118db","fc16a62aa2da45ce9d0033a1038365a6","ca5fe4cb9df646509879351fe57d3b34","fe037727e6344d0ebc7666336b9d8c92","773207ff49ed462198b8069b4a3599a2","f3a32a5b1d6946bc862af6ae960f5476","c5c5bc8e5a2048b881059ab439c0791a"]},"executionInfo":{"elapsed":2215,"status":"ok","timestamp":1683680409361,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"jwvoS1RjyJw3","outputId":"efbe314c-d75b-498b-90c5-10162efacdbb"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19fced259a97455388584029ade8b555","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ab1d4ee45214cdc97d235d527d2a8f8","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e526efe0f104f55babf0db5fdb4b777","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":1114,"status":"ok","timestamp":1683680410470,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"HuIdphoS21tC"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from transformers import BertTokenizer\n","import pandas as pd\n","\n","class Dataset():\n","\n","    def __init__(self, data, maxlen):\n","\n","        #Store the contents of the file in a pandas dataframe\n","        self.data = data\n","\n","        #Initialize the BERT tokenizer\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","        self.maxlen = maxlen\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","\n","        #Selecting the sentence and label at the specified index in the data frame\n","        sentence1 = self.data[index][0][0]\n","        sentence2 = self.data[index][0][1]\n","        label = self.data[index][1]\n","\n","        #Preprocessing the text to be suitable for BERT\n","        tokens1 = tokenizer.tokenize(sentence1)\n","        tokens2 = tokenizer.tokenize(sentence2)\n","        tokens1 = ['[CLS]'] + tokens1 + ['[SEP]']\n","        tokens2 = ['[CLS]'] + tokens2 + ['[SEP]']\n","        if len(tokens1) < self.maxlen:\n","            tokens1 = tokens1 + ['[PAD]' for _ in range(self.maxlen - len(tokens1))] #Padding sentences\n","        else:\n","            tokens1 = tokens1[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n","\n","        if len(tokens2) < self.maxlen:\n","            tokens2 = tokens2 + ['[PAD]' for _ in range(self.maxlen - len(tokens2))] #Padding sentences\n","        else:\n","            tokens2 = tokens2[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n","\n","        tokens_ids1 = self.tokenizer.convert_tokens_to_ids(tokens1) #Obtaining the indices of the tokens in the BERT Vocabulary\n","        tokens_ids_tensor1 = torch.tensor(tokens_ids1) #Converting the list to a pytorch tensor\n","\n","        tokens_ids2 = self.tokenizer.convert_tokens_to_ids(tokens2) #Obtaining the indices of the tokens in the BERT Vocabulary\n","        tokens_ids_tensor2 = torch.tensor(tokens_ids2) #Converting the list to a pytorch tensor\n","\n","        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n","        attn_mask1 = (tokens_ids_tensor1 != 0).long()\n","        attn_mask2 = (tokens_ids_tensor2 != 0).long()\n","\n","\n","\n","        return tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2,  label"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":873,"status":"ok","timestamp":1683680411341,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"qvOcemHR_bHt"},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","#Creating instances of training and development set\n","#maxlen sets the maximum length a sentence can have\n","#any sentence longer than this length is truncated to the maxlen size\n","train_set = Dataset(training_data, maxlen = 512)\n","dev_set = Dataset(dev_data, maxlen = 512)\n","test_set = Dataset(test_data, maxlen = 512)\n","\n","#Creating intsances of training and development dataloaders\n","train_loader = DataLoader(train_set, batch_size = 4, shuffle = True, num_workers = 2)\n","dev_loader = DataLoader(dev_set, batch_size = 4, shuffle = True, num_workers = 2)\n","test_loader = DataLoader(test_set, batch_size = 4, shuffle = True, num_workers = 2)"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1683680411346,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"srZ-42Pz_oyO"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from transformers import BertModel\n","\n","class RelatednessClassifier(nn.Module):\n","\n","    def __init__(self):\n","        super(RelatednessClassifier, self).__init__()\n","        #Instantiating BERT model object \n","        self.bert_layer1 = BertModel.from_pretrained('bert-base-uncased')\n","        self.bert_layer2 = BertModel.from_pretrained('bert-base-uncased')\n","\n","        \n","        #Classification layer\n","        #input dimension is 768 because [CLS] embedding has a dimension of 768\n","        #output dimension is 1 because we're working with a binary classification problem\n","        self.cls_layer = nn.Linear(1537, 1)\n","\n","    def forward(self, seq1, attn_masks1, seq2, attn_masks2):\n","        '''\n","        Inputs:\n","            -seq : Tensor of shape [B, T] containing token ids of sequences\n","            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n","        '''\n","        batch_size = seq1.size(0)\n","        #Feeding the input to BERT model to obtain contextualized representations\n","        claim_outputs = self.bert_layer1(seq1, attention_mask = attn_masks1, return_dict=True)\n","        claim_cont_reps = claim_outputs.last_hidden_state\n","\n","        #Obtaining the representation of [CLS] head (the first token)\n","        claim_cls_reps = claim_cont_reps[:, 0]\n","\n","        #Feeding the input to BERT model to obtain contextualized representations\n","        evid_outputs = self.bert_layer2(seq2, attention_mask = attn_masks2, return_dict=True)\n","        evid_cont_reps = evid_outputs.last_hidden_state\n","\n","        #Obtaining the representation of [CLS] head (the first token)\n","        evid_cls_reps = evid_cont_reps[:, 0]\n","\n","        # Concatenate the two output tensors along the last dimension (i.e., the features dimension)\n","        concat_output = torch.cat((claim_cls_reps, evid_cls_reps), dim=-1)\n","\n","        # Calculate the Euclidean distance between the two output tensors and flatten the result\n","        distances = []\n","        for i in range(batch_size):\n","            distance = torch.dist(claim_cls_reps[i], evid_cls_reps[i], p=2)\n","            distances.append(distance)\n","        distances = torch.flatten(torch.stack(distances)).unsqueeze(1)\n","\n","        # Concatenate the flattened distance with the concatenated output tensor\n","        concat_output = torch.cat((concat_output, distances), dim=-1)\n","\n","        #Feeding cls_rep to the classifier layer\n","        logits = self.cls_layer(concat_output)\n","\n","        return logits\n","    \n","\n","    def get_claim_embedding(self, seq1, attn_masks1):\n","        #Feeding the input to BERT model to obtain contextualized representations\n","        claim_outputs = self.bert_layer1(seq1, attention_mask = attn_masks1, return_dict=True)\n","        claim_cont_reps = claim_outputs.last_hidden_state\n","\n","        #Obtaining the representation of [CLS] head (the first token)\n","        claim_cls_reps = claim_cont_reps[:, 0]\n","\n","        return claim_cls_reps\n","    \n","\n","    def get_evid_embedding(self, seq2, attn_masks2):\n","        #Feeding the input to BERT model to obtain contextualized representations\n","        evid_outputs = self.bert_layer2(seq2, attention_mask = attn_masks2, return_dict=True)\n","        evid_cont_reps = evid_outputs.last_hidden_state\n","\n","        #Obtaining the representation of [CLS] head (the first token)\n","        evid_cls_reps = evid_cont_reps[:, 0]\n","\n","        return evid_cont_reps\n","    \n","\n","    def neural_layer(self, claim_cls_reps, evid_cls_reps):\n","\n","        # Concatenate the two output tensors along the last dimension (i.e., the features dimension)\n","        batch_size = claim_cls_reps.size(0)\n","        concat_output = torch.cat((claim_cls_reps, evid_cls_reps), dim=-1)\n","        \n","        # Calculate the Euclidean distance between the two output tensors and flatten the result\n","        distances = []\n","        for i in range(batch_size):\n","            distance = torch.dist(claim_cls_reps[i], evid_cls_reps[i], p=2)\n","            distances.append(distance)\n","        distances = torch.flatten(torch.stack(distances))\n","        \n","        # Concatenate the flattened distance with the concatenated output tensor\n","        concat_output = torch.cat((concat_output, distances), dim=-1)\n","\n","        #Feeding cls_rep to the classifier layer\n","        logits = self.cls_layer(concat_output)\n","        \n","\n","        return logits"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1683680411348,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"uJDoCv7AB9B5","outputId":"abe58dd0-8c60-4394-9ae5-056362618f0e"},"outputs":[{"data":{"text/plain":["12"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":208,"referenced_widgets":["7a3fcd5d41954cd792dd1a090ea35675","206c03deb81246f9a29b7c67068890ff","ba0a7cb82bb84eaa86ef1771708b15fc","b302ad0ebfa549d694f6507a405f26da","e68f719f28424268860b10cce8c851f0","70fb7bc7b0df400bae48129c0122fdc7","f14076efef7848daa057e9212fe4a10c","e07a1e5a23004236923bc726eb89587f","c1e1d5955ccd4576a6bd3835dd2dff80","0e69aa654b6f433db150102481799868","4bc963ef40b7451e8bbc5e8bc2272de3"]},"executionInfo":{"elapsed":30469,"status":"ok","timestamp":1683680441792,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"fA0faPfGAeLl","outputId":"bc764e4a-946e-4667-e606-ece1520f6fe1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7a3fcd5d41954cd792dd1a090ea35675","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Done creating the sentiment classifier.\n"]}],"source":["gpu = 0 #gpu ID\n","\n","print(\"Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\")\n","net = RelatednessClassifier()\n","net.cuda(gpu) #Enable gpu support for the model\n","print(\"Done creating the sentiment classifier.\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Setup Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CGlc0FwVAlHB"},"outputs":[],"source":["import torch.nn as nn\n","import torch.optim as optim\n","\n","criterion = nn.BCEWithLogitsLoss()\n","opti = optim.Adam(net.parameters(), lr = 2e-5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L7RR7ohEAnjy"},"outputs":[],"source":["def get_accuracy_from_logits(logits, labels):\n","    probs = torch.sigmoid(logits.unsqueeze(-1))\n","    soft_probs = (probs > 0.5).long()\n","    acc = (soft_probs.squeeze() == labels).float().mean()\n","    return acc\n","\n","def evaluate(net, criterion, dataloader, gpu):\n","    net.eval()\n","\n","    mean_acc, mean_loss = 0, 0\n","    count = 0\n","\n","    with torch.no_grad():\n","        for tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2, label in dataloader:\n","            tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2, label = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu), tokens_ids_tensor2.cuda(gpu), attn_mask2.cuda(gpu), label.cuda(gpu)\n","            logits = net(tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2)\n","            mean_loss += criterion(logits.squeeze(-1), label.float()).item()\n","            mean_acc += get_accuracy_from_logits(logits, label)\n","            count += 1\n","\n","    return mean_acc / count, mean_loss / count"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eBze9eaUAqLg"},"outputs":[],"source":["import time\n","\n","def train(net, criterion, opti, train_loader, dev_loader, max_eps, gpu):\n","\n","    best_acc = 0\n","    st = time.time()\n","    for ep in range(max_eps):\n","        \n","        net.train()\n","        for it, (tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2, label) in enumerate(train_loader):\n","            #Clear gradients\n","            opti.zero_grad()  \n","            #Converting these to cuda tensors\n","            tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2, label = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu), tokens_ids_tensor2.cuda(gpu), attn_mask2.cuda(gpu), label.cuda(gpu)\n","\n","            #Obtaining the logits from the model\n","            logits = net(tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2)\n","\n","            #Computing loss\n","            loss = criterion(logits.squeeze(-1), label.float())\n","\n","            #Backpropagating the gradients\n","            loss.backward()\n","\n","            #Optimization step\n","            opti.step()\n","              \n","            if it % 100 == 0:\n","                \n","                acc = get_accuracy_from_logits(logits, label)\n","                print(\"Iteration {} of epoch {} complete. Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n","                st = time.time()\n","\n","        \n","        dev_acc, dev_loss = evaluate(net, criterion, dev_loader, gpu)\n","        print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(ep, dev_acc, dev_loss))\n","        if dev_acc > best_acc:\n","            print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n","            best_acc = dev_acc\n","            torch.save(net.state_dict(), './drive/My Drive/LAB/COMP90042 A3/models/Retrievers/Retriever_SBert_reduced.dat')\n","            torch.save(net, './drive/My Drive/LAB/COMP90042 A3/models/Retrievers/Retriever_SBert_reduced.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683379441069,"user":{"displayName":"Lang Chen","userId":"02743582657302157093"},"user_tz":-600},"id":"QtKuWB_yB-JB","outputId":"b0e61939-fc5e-4ec1-bf18-21662171d6e9"},"outputs":[{"data":{"text/plain":["8"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Read In Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5mhGZTSBB2S"},"outputs":[],"source":["num_epoch = 5\n","\n","#fine-tune the model\n","train(net, criterion, opti, train_loader, dev_loader, num_epoch, gpu)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11339,"status":"ok","timestamp":1683379452403,"user":{"displayName":"Lang Chen","userId":"02743582657302157093"},"user_tz":-600},"id":"XExrRgJ6r1Uv","outputId":"0ef7c165-6624-4dc9-cfe3-25725b11e238"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["net.load_state_dict(torch.load('./drive/My Drive/LAB/COMP90042 A3/models/Retrievers/Retriever_SBert_reduced.dat'))"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":19158,"status":"ok","timestamp":1683680460936,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"lNE4FUvKAor6"},"outputs":[],"source":["net = torch.load('./drive/My Drive/LAB/COMP90042 A3/models/Retrievers/Retriever_SBert_reduced.pt')"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1683680460985,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"HzjUr6tcAtxL","outputId":"01b4768c-e28e-4313-9ca8-35e7c4909157"},"outputs":[{"data":{"text/plain":["RelatednessClassifier(\n","  (bert_layer1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (bert_layer2): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (cls_layer): Linear(in_features=1537, out_features=1, bias=True)\n",")"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["net.eval()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Make Predictions (to get Retrievals)"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":291,"status":"ok","timestamp":1683680460988,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"sLugJKoDMqbV"},"outputs":[],"source":["class PredictDataset():\n","\n","    def __init__(self, data, maxlen):\n","\n","        #Store the contents of the file in a pandas dataframe\n","        self.data = data\n","\n","        #Initialize the BERT tokenizer\n","        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","        self.maxlen = maxlen\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","\n","        #Selecting the sentence and label at the specified index in the data frame\n","        sentence1 = self.data[index][0][0]\n","        sentence2 = self.data[index][0][1]\n","\n","        #Preprocessing the text to be suitable for BERT\n","        tokens1 = tokenizer.tokenize(sentence1)\n","        tokens2 = tokenizer.tokenize(sentence2)\n","        tokens1 = ['[CLS]'] + tokens1 + ['[SEP]']\n","        tokens2 = ['[CLS]'] + tokens2 + ['[SEP]']\n","        if len(tokens1) < self.maxlen:\n","            tokens1 = tokens1 + ['[PAD]' for _ in range(self.maxlen - len(tokens1))] #Padding sentences\n","        else:\n","            tokens1 = tokens1[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n","\n","        if len(tokens2) < self.maxlen:\n","            tokens2 = tokens2 + ['[PAD]' for _ in range(self.maxlen - len(tokens2))] #Padding sentences\n","        else:\n","            tokens2 = tokens2[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n","\n","        tokens_ids1 = self.tokenizer.convert_tokens_to_ids(tokens1) #Obtaining the indices of the tokens in the BERT Vocabulary\n","        tokens_ids_tensor1 = torch.tensor(tokens_ids1) #Converting the list to a pytorch tensor\n","\n","        tokens_ids2 = self.tokenizer.convert_tokens_to_ids(tokens2) #Obtaining the indices of the tokens in the BERT Vocabulary\n","        tokens_ids_tensor2 = torch.tensor(tokens_ids2) #Converting the list to a pytorch tensor\n","\n","        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n","        attn_mask1 = (tokens_ids_tensor1 != 0).long()\n","        attn_mask2 = (tokens_ids_tensor2 != 0).long()\n","\n","\n","\n","        return tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":295,"status":"ok","timestamp":1683680460993,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"C5cl5ufaBXUf","outputId":"679cd37a-7804-4581-c510-5e4651390317"},"outputs":[{"data":{"text/plain":["9"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":263,"status":"ok","timestamp":1683680460994,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"U9qPoCOh_x-7"},"outputs":[],"source":["EVIDENCE = [(claim,evidence[claim]) for claim in scientific_claims_id]"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":271,"status":"ok","timestamp":1683680461004,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"lPuflekhLI1c"},"outputs":[],"source":["def get_retrievals(claims, file_name, SIZE=32):\n","  try:\n","    with open(f'./drive/My Drive/LAB/COMP90042 A3/predictions/Retrievals/{file_name}.pickle', 'rb') as f:\n","      retrievals = pickle.load(f)\n","  except:\n","      retrievals = {}\n","\n","  EVIDENCE.sort(key = lambda x:x[0])\n","\n","  i = 0\n","  for id in claims:\n","    if id in retrievals:\n","      print('pass:', id)\n","      continue\n","\n","    print(id)\n","    data_for_predict = []\n","\n","    claim_text = claims[id]['claim_text']\n","\n","    for evid in EVIDENCE:\n","\n","      evid_text = evid[1]\n","\n","      data_for_predict.append((claim_text, evid_text))\n","\n","    set_for_predict = PredictDataset(data_for_predict, maxlen = 512)\n","\n","    predict_loader = DataLoader(set_for_predict, batch_size = SIZE, num_workers = 2)\n","    \n","    predicted_logit = list()\n","    with torch.no_grad():\n","      for it, (tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2) in enumerate(predict_loader):\n","        \n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2 = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu), tokens_ids_tensor2.cuda(gpu), attn_mask2.cuda(gpu)\n","\n","        logits = net(tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2).tolist()\n","        logits = [x[0] for x in logits]\n","        \n","        for prediction in zip([claim_id for claim_id in EVIDENCE[it*SIZE:(it+1)*SIZE+1]], logits):\n","          predicted_logit.append(prediction)\n","      \n","      predicted_logit.sort(key = lambda x:x[1], reverse = True)\n","      predicted_logit = predicted_logit[:5]\n","\n","      retrievals[id] = {'evidences': [x[0] for x in predicted_logit]}\n","\n","      with open(f'./drive/My Drive/LAB/COMP90042 A3/predictions/Retrievals/{file_name}.pickle', 'wb') as f:\n","          pickle.dump(retrievals, f)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1863,"status":"ok","timestamp":1683680579746,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"LjA24LYuMf0w","outputId":"e788625d-e870-4e9c-c81a-2e3a43c09541"},"outputs":[{"name":"stdout","output_type":"stream","text":["pass: claim-752\n","pass: claim-375\n","pass: claim-1266\n","pass: claim-871\n","pass: claim-2164\n","pass: claim-1607\n","pass: claim-761\n","pass: claim-1718\n","pass: claim-1273\n","pass: claim-1786\n","pass: claim-2796\n","pass: claim-2580\n","pass: claim-1219\n","pass: claim-75\n","pass: claim-2813\n","pass: claim-2335\n","pass: claim-161\n","pass: claim-2243\n","pass: claim-1256\n","pass: claim-506\n","pass: claim-369\n","pass: claim-2184\n","pass: claim-1057\n","pass: claim-104\n","pass: claim-1975\n","pass: claim-139\n","pass: claim-2062\n","pass: claim-1160\n","pass: claim-2679\n","pass: claim-2662\n","pass: claim-1490\n","pass: claim-2768\n","pass: claim-2168\n","pass: claim-785\n","pass: claim-2426\n","pass: claim-1292\n","pass: claim-993\n","pass: claim-2593\n","pass: claim-1567\n","pass: claim-1834\n","pass: claim-856\n","pass: claim-540\n","pass: claim-757\n","pass: claim-1407\n","pass: claim-3070\n","pass: claim-1745\n","pass: claim-1515\n","pass: claim-1519\n","pass: claim-3069\n","pass: claim-677\n","pass: claim-765\n","pass: claim-2275\n","pass: claim-1113\n","pass: claim-2611\n","pass: claim-2060\n","pass: claim-2326\n","pass: claim-1087\n","pass: claim-2867\n","pass: claim-2300\n","pass: claim-2250\n","pass: claim-2429\n","pass: claim-3051\n","pass: claim-1549\n","pass: claim-261\n","pass: claim-2230\n","pass: claim-2579\n","pass: claim-1416\n","pass: claim-2497\n","pass: claim-811\n","pass: claim-1896\n","pass: claim-2819\n","pass: claim-2643\n","pass: claim-1775\n","pass: claim-316\n","pass: claim-896\n","pass: claim-331\n","pass: claim-2574\n","pass: claim-342\n","pass: claim-2034\n","pass: claim-578\n","pass: claim-976\n","pass: claim-1097\n","pass: claim-609\n","pass: claim-173\n","pass: claim-1222\n","pass: claim-2441\n","pass: claim-756\n","pass: claim-2577\n","pass: claim-2890\n","pass: claim-2478\n","pass: claim-2399\n","pass: claim-3091\n","pass: claim-141\n","pass: claim-1933\n","pass: claim-1689\n","pass: claim-443\n","pass: claim-2037\n","pass: claim-1734\n","pass: claim-2093\n","pass: claim-1400\n","pass: claim-1638\n","pass: claim-3075\n","pass: claim-38\n","pass: claim-1643\n","pass: claim-1259\n","pass: claim-1605\n","pass: claim-1711\n","pass: claim-2236\n","pass: claim-1040\n","pass: claim-392\n","pass: claim-368\n","pass: claim-559\n","pass: claim-2583\n","pass: claim-2609\n","pass: claim-492\n","pass: claim-1420\n","pass: claim-1089\n","pass: claim-1467\n","pass: claim-444\n","pass: claim-803\n","pass: claim-1668\n","pass: claim-742\n","pass: claim-846\n","pass: claim-2119\n","pass: claim-1167\n","pass: claim-623\n","pass: claim-2882\n","pass: claim-1698\n","pass: claim-181\n","pass: claim-281\n","pass: claim-2809\n","pass: claim-1928\n","pass: claim-2787\n","pass: claim-478\n","pass: claim-988\n","pass: claim-266\n","pass: claim-2282\n","pass: claim-2895\n","pass: claim-349\n","pass: claim-2101\n","pass: claim-897\n","pass: claim-3063\n","pass: claim-386\n","pass: claim-2691\n","pass: claim-530\n","pass: claim-2979\n","pass: claim-665\n","pass: claim-199\n","pass: claim-490\n","pass: claim-2400\n","pass: claim-204\n","pass: claim-1426\n","pass: claim-698\n","pass: claim-1021\n"]}],"source":["get_retrievals(dev_claims, 'Retrieval_SBERT_reduced_dev', SIZE=32)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3321,"status":"ok","timestamp":1683680465252,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"NsoiYxAGMqvc","outputId":"9ba8d2f3-1c78-40bc-b87d-9f0a9ed55041"},"outputs":[{"name":"stdout","output_type":"stream","text":["pass: claim-1898\n","pass: claim-2276\n","pass: claim-564\n","pass: claim-3003\n","pass: claim-2173\n","pass: claim-1818\n","pass: claim-2903\n","pass: claim-1362\n","pass: claim-2726\n","pass: claim-1466\n","pass: claim-2040\n","pass: claim-311\n","pass: claim-1855\n","pass: claim-72\n","pass: claim-840\n","pass: claim-1075\n","pass: claim-2374\n","pass: claim-2305\n","pass: claim-904\n","pass: claim-1276\n","pass: claim-447\n","pass: claim-1673\n","pass: claim-2181\n","pass: claim-1360\n","pass: claim-2901\n","pass: claim-586\n","pass: claim-788\n","pass: claim-3009\n","pass: claim-2837\n","pass: claim-1553\n","pass: claim-1649\n","pass: claim-2682\n","pass: claim-1719\n","pass: claim-787\n","pass: claim-2430\n","pass: claim-3062\n","pass: claim-1286\n","pass: claim-1465\n","pass: claim-1067\n","pass: claim-2745\n","pass: claim-2720\n","pass: claim-2032\n","pass: claim-1991\n","pass: claim-920\n","pass: claim-1421\n","pass: claim-1555\n","pass: claim-2358\n","pass: claim-1565\n","pass: claim-582\n","pass: claim-1399\n","pass: claim-555\n","pass: claim-1923\n","pass: claim-1658\n","pass: claim-512\n","pass: claim-248\n","pass: claim-1980\n","pass: claim-1492\n","pass: claim-948\n","pass: claim-2912\n","pass: claim-2004\n","pass: claim-1717\n","pass: claim-995\n","pass: claim-3079\n","pass: claim-2068\n","pass: claim-1817\n","pass: claim-2223\n","pass: claim-1825\n","pass: claim-2009\n","pass: claim-2542\n","pass: claim-508\n","pass: claim-189\n","pass: claim-44\n","pass: claim-1376\n","pass: claim-939\n","pass: claim-1357\n","pass: claim-849\n","pass: claim-418\n","pass: claim-2272\n","pass: claim-1983\n","pass: claim-1504\n","pass: claim-1626\n","pass: claim-1510\n","pass: claim-1463\n","pass: claim-666\n","pass: claim-1434\n","pass: claim-2694\n","pass: claim-1678\n","pass: claim-1462\n","pass: claim-1871\n","pass: claim-2312\n","pass: claim-337\n","pass: claim-2214\n","pass: claim-962\n","pass: claim-434\n","pass: claim-2827\n","pass: claim-1049\n","pass: claim-1369\n","pass: claim-728\n","pass: claim-1875\n","pass: claim-1819\n","pass: claim-378\n","pass: claim-1623\n","pass: claim-1270\n","pass: claim-3000\n","pass: claim-1495\n","pass: claim-2834\n","pass: claim-807\n","pass: claim-1932\n","pass: claim-2916\n","pass: claim-1151\n","pass: claim-169\n","pass: claim-1592\n","pass: claim-442\n","pass: claim-590\n","pass: claim-1178\n","pass: claim-1406\n","pass: claim-1874\n","pass: claim-1562\n","pass: claim-6\n","pass: claim-2522\n","pass: claim-1793\n","pass: claim-2457\n","pass: claim-2049\n","pass: claim-1971\n","pass: claim-2712\n","pass: claim-3130\n","pass: claim-800\n","pass: claim-399\n","pass: claim-2290\n","pass: claim-2047\n","pass: claim-1150\n","pass: claim-198\n","pass: claim-1524\n","pass: claim-246\n","pass: claim-3008\n","pass: claim-412\n","pass: claim-2641\n","pass: claim-2365\n","pass: claim-388\n","pass: claim-2229\n","pass: claim-3099\n","pass: claim-1703\n","pass: claim-3066\n","pass: claim-1831\n","pass: claim-1142\n","pass: claim-863\n","pass: claim-1389\n","pass: claim-2565\n","pass: claim-100\n","pass: claim-2390\n","pass: claim-676\n","pass: claim-2320\n","pass: claim-2387\n","pass: claim-2612\n"]}],"source":["get_retrievals(test_claims, 'Retrieval_SBERT_reduced_test', SIZE=32)"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1038,"status":"ok","timestamp":1683680586604,"user":{"displayName":"Ron Chen","userId":"07154237521678438544"},"user_tz":-600},"id":"eIZfSYjEMj6u","outputId":"1f68b19e-5135-4caa-9519-7b562bc8a0b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["pass: claim-2967\n","pass: claim-979\n","pass: claim-1609\n","pass: claim-1020\n","pass: claim-2599\n","pass: claim-2110\n","pass: claim-1135\n","pass: claim-712\n","pass: claim-1307\n","pass: claim-148\n","pass: claim-903\n","pass: claim-2942\n","pass: claim-1001\n","pass: claim-1034\n","pass: claim-1009\n","pass: claim-770\n","pass: claim-3074\n","pass: claim-1761\n","pass: claim-1475\n","pass: claim-477\n","pass: claim-1378\n","pass: claim-503\n","pass: claim-2751\n","pass: claim-2575\n","pass: claim-30\n","pass: claim-2994\n","pass: claim-55\n","pass: claim-1271\n","pass: claim-2248\n","pass: claim-532\n","pass: claim-556\n","pass: claim-1173\n","pass: claim-539\n","pass: claim-893\n","pass: claim-2857\n","pass: claim-109\n","pass: claim-2476\n","pass: claim-3038\n","pass: claim-3127\n","pass: claim-474\n","pass: claim-2464\n","pass: claim-2427\n","pass: claim-2167\n","pass: claim-812\n","pass: claim-2590\n","pass: claim-404\n","pass: claim-2977\n","pass: claim-2673\n","pass: claim-2509\n","pass: claim-138\n","pass: claim-952\n","pass: claim-1691\n","pass: claim-1741\n","pass: claim-1202\n","pass: claim-1028\n","pass: claim-28\n","pass: claim-275\n","pass: claim-350\n","pass: claim-2204\n","pass: claim-1604\n","pass: claim-3119\n","pass: claim-2150\n","pass: claim-21\n","pass: claim-2013\n","pass: claim-467\n","pass: claim-2754\n","pass: claim-2797\n","pass: claim-1771\n","pass: claim-1908\n","pass: claim-2000\n","pass: claim-2084\n","pass: claim-1237\n","pass: claim-400\n","pass: claim-1508\n","pass: claim-520\n","pass: claim-3064\n","pass: claim-1588\n","pass: claim-1488\n","pass: claim-2733\n","pass: claim-809\n","pass: claim-763\n","pass: claim-454\n","pass: claim-1853\n","pass: claim-2838\n","pass: claim-2028\n","pass: claim-2434\n","pass: claim-298\n","pass: claim-338\n","pass: claim-1672\n","pass: claim-2840\n","pass: claim-1425\n","pass: claim-1985\n","pass: claim-1156\n","pass: claim-2870\n","pass: claim-2898\n","pass: claim-2329\n","pass: claim-1998\n","pass: claim-2209\n","pass: claim-1582\n","pass: claim-3072\n","pass: claim-381\n","pass: claim-398\n","pass: claim-1560\n","pass: claim-2246\n","pass: claim-2774\n","pass: claim-972\n","pass: claim-1531\n","pass: claim-2592\n","pass: claim-2468\n","pass: claim-463\n","pass: claim-616\n","pass: claim-1240\n","pass: claim-2951\n","pass: claim-1977\n","pass: claim-942\n","pass: claim-2755\n","pass: claim-1230\n","pass: claim-3123\n","pass: claim-1684\n","pass: claim-839\n","pass: claim-2423\n","pass: claim-1243\n","pass: claim-494\n","pass: claim-1458\n","pass: claim-461\n","pass: claim-1304\n","pass: claim-2564\n","pass: claim-2121\n","pass: claim-2631\n","pass: claim-1141\n","pass: claim-2398\n","pass: claim-1048\n","pass: claim-2783\n","pass: claim-1003\n","pass: claim-1872\n","pass: claim-1842\n","pass: claim-2411\n","pass: claim-2428\n","pass: claim-1198\n","pass: claim-678\n","pass: claim-2105\n","pass: claim-648\n","pass: claim-822\n","pass: claim-2561\n","pass: claim-2219\n","pass: claim-1343\n","pass: claim-1351\n","pass: claim-2347\n","pass: claim-293\n","pass: claim-910\n","pass: claim-2815\n","pass: claim-1652\n","pass: claim-1212\n"]}],"source":["get_retrievals(future_claims, 'Retrieval_SBERT_reduced_future', SIZE=32)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aY2ic3lINAK8"},"outputs":[],"source":["# with open('./drive/My Drive/LAB/COMP90042 A3/notebooks/test_predictions_sentence.pickle', 'rb') as f:\n","#   final_test_predictions_sentence = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SX-16tDG21DY"},"outputs":[],"source":["# final_test_predictions_sentence = {}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1229161,"status":"ok","timestamp":1683289988999,"user":{"displayName":"Zeping Chen","userId":"17844763960576389588"},"user_tz":-600},"id":"qNCjJgL9M_Te","outputId":"848c3d97-8a41-4bfa-ed44-509624fd201a"},"outputs":[{"name":"stdout","output_type":"stream","text":["pass: claim-1898\n","pass: claim-2276\n","pass: claim-564\n","pass: claim-3003\n","pass: claim-2173\n","pass: claim-1818\n","pass: claim-2903\n","pass: claim-1362\n","pass: claim-2726\n","pass: claim-1466\n","pass: claim-2040\n","pass: claim-311\n","pass: claim-1855\n","pass: claim-72\n","pass: claim-840\n","pass: claim-1075\n","pass: claim-2374\n","pass: claim-2305\n","pass: claim-904\n","pass: claim-1276\n","pass: claim-447\n","pass: claim-1673\n","pass: claim-2181\n","pass: claim-1360\n","pass: claim-2901\n","pass: claim-586\n","pass: claim-788\n","pass: claim-3009\n","pass: claim-2837\n","pass: claim-1553\n","pass: claim-1649\n","pass: claim-2682\n","pass: claim-1719\n","pass: claim-787\n","pass: claim-2430\n","pass: claim-3062\n","pass: claim-1286\n","pass: claim-1465\n","pass: claim-1067\n","pass: claim-2745\n","pass: claim-2720\n","pass: claim-2032\n","pass: claim-1991\n","pass: claim-920\n","pass: claim-1421\n","pass: claim-1555\n","pass: claim-2358\n","pass: claim-1565\n","pass: claim-582\n","pass: claim-1399\n","pass: claim-555\n","pass: claim-1923\n","pass: claim-1658\n","pass: claim-512\n","pass: claim-248\n","pass: claim-1980\n","pass: claim-1492\n","pass: claim-948\n","pass: claim-2912\n","pass: claim-2004\n","pass: claim-1717\n","pass: claim-995\n","pass: claim-3079\n","pass: claim-2068\n","claim-1817\n","pass: claim-2223\n","claim-1825\n","pass: claim-2009\n","claim-2542\n","pass: claim-508\n","claim-189\n","pass: claim-44\n","claim-1376\n","pass: claim-939\n","claim-1357\n","pass: claim-849\n","claim-418\n","pass: claim-2272\n","claim-1983\n","pass: claim-1504\n","pass: claim-1626\n","pass: claim-1510\n","pass: claim-1463\n","pass: claim-666\n","pass: claim-1434\n","pass: claim-2694\n","pass: claim-1678\n","pass: claim-1462\n","pass: claim-1871\n","pass: claim-2312\n","pass: claim-337\n","pass: claim-2214\n","pass: claim-962\n","pass: claim-434\n","pass: claim-2827\n","pass: claim-1049\n","pass: claim-1369\n","pass: claim-728\n","pass: claim-1875\n","pass: claim-1819\n","pass: claim-378\n","pass: claim-1623\n","pass: claim-1270\n","pass: claim-3000\n","pass: claim-1495\n","pass: claim-2834\n","pass: claim-807\n","pass: claim-1932\n","pass: claim-2916\n","pass: claim-1151\n","pass: claim-169\n","pass: claim-1592\n","pass: claim-442\n","pass: claim-590\n","pass: claim-1178\n","pass: claim-1406\n","pass: claim-1874\n","pass: claim-1562\n","pass: claim-6\n","pass: claim-2522\n","pass: claim-1793\n","pass: claim-2457\n","pass: claim-2049\n","pass: claim-1971\n","pass: claim-2712\n","pass: claim-3130\n","pass: claim-800\n","pass: claim-399\n","pass: claim-2290\n","pass: claim-2047\n","pass: claim-1150\n","pass: claim-198\n","pass: claim-1524\n","pass: claim-246\n","pass: claim-3008\n","pass: claim-412\n","pass: claim-2641\n","pass: claim-2365\n","pass: claim-388\n","pass: claim-2229\n","pass: claim-3099\n","pass: claim-1703\n","pass: claim-3066\n","pass: claim-1831\n","pass: claim-1142\n","pass: claim-863\n","pass: claim-1389\n","pass: claim-2565\n","pass: claim-100\n","pass: claim-2390\n","claim-676\n","pass: claim-2320\n","claim-2387\n","pass: claim-2612\n"]}],"source":["# SIZE = 32\n","\n","# EVIDENCE.sort(key = lambda x:x[0])\n","\n","# i = 0\n","# for id in test_claims:\n","#   if id in final_test_predictions_sentence:\n","#     print('pass:', id)\n","#     continue\n","\n","#   print(id)\n","#   test_data_for_predict = []\n","\n","#   claim_text = test_claims[id]['claim_text']\n","\n","#   for evid in EVIDENCE:\n","\n","#     evid_text = evid[1]\n","\n","#     test_data_for_predict.append((claim_text, evid_text))\n","\n","#   test_set_for_predict = PredictDataset(test_data_for_predict, maxlen = 512)\n","\n","#   test_predict_loader = DataLoader(test_set_for_predict, batch_size = SIZE, num_workers = 2)\n","  \n","#   predicted_logit = list()\n","#   with torch.no_grad():\n","#     for it, (tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2) in enumerate(dev_predict_loader):\n","      \n","#       torch.cuda.empty_cache()\n","#       gc.collect()\n","#       tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2 = tokens_ids_tensor1.cuda(gpu), attn_mask1.cuda(gpu), tokens_ids_tensor2.cuda(gpu), attn_mask2.cuda(gpu)\n","\n","#       logits = net(tokens_ids_tensor1, attn_mask1, tokens_ids_tensor2, attn_mask2).tolist()\n","#       logits = [x[0] for x in logits]\n","      \n","#       for prediction in zip([claim_id for claim_id in EVIDENCE[it*SIZE:(it+1)*SIZE+1]], logits):\n","#         predicted_logit.append(prediction)\n","    \n","#     predicted_logit.sort(key = lambda x:x[1], reverse = True)\n","#     predicted_logit = predicted_logit[:5]\n","\n","#     final_test_predictions_sentence[id] = {'evidences': [x[0] for x in predicted_logit]}\n","\n","#     with open('./drive/My Drive/LAB/COMP90042 A3/notebooks/test_predictions_sentence.pickle', 'wb') as f:\n","#         pickle.dump(final_test_predictions_sentence, f)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K78bBI8JAUTT"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"01c3cf98bb4f4caa94c6a436ad8f185b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"092633a12534423188982d34daa01d20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_01c3cf98bb4f4caa94c6a436ad8f185b","placeholder":"​","style":"IPY_MODEL_915bff8ea4fd4fa387abdb9025b24fcb","value":"Downloading (…)okenizer_config.json: 100%"}},"0e526efe0f104f55babf0db5fdb4b777":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_217ac96d33974f5ea07c8afa8b1206ce","IPY_MODEL_9a8b59aa137742909bca6d6b85d3e0a2","IPY_MODEL_ba4a9ecb04b847c5ba286c65c7c30cef"],"layout":"IPY_MODEL_4f1a4a4e486c457ca70427d16f4118db"}},"0e69aa654b6f433db150102481799868":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19fced259a97455388584029ade8b555":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7dc2510ff41447a88c9616fc910c2fcb","IPY_MODEL_c87f6fac4e7f43168f0ed3217b8311e1","IPY_MODEL_d1a2435a3ab141f19c5f75e1b3522a21"],"layout":"IPY_MODEL_614f2d66fd344a25b7b6383980cd7155"}},"206c03deb81246f9a29b7c67068890ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70fb7bc7b0df400bae48129c0122fdc7","placeholder":"​","style":"IPY_MODEL_f14076efef7848daa057e9212fe4a10c","value":"Downloading pytorch_model.bin: 100%"}},"217ac96d33974f5ea07c8afa8b1206ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fc16a62aa2da45ce9d0033a1038365a6","placeholder":"​","style":"IPY_MODEL_ca5fe4cb9df646509879351fe57d3b34","value":"Downloading (…)lve/main/config.json: 100%"}},"3d8f28d0299a43ffba66f77ac5af2445":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4bc963ef40b7451e8bbc5e8bc2272de3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4f1a4a4e486c457ca70427d16f4118db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"512e9c26893c4863a13fc350f300d298":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ab1d4ee45214cdc97d235d527d2a8f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_092633a12534423188982d34daa01d20","IPY_MODEL_80f46bd96ade485495becef95abb7e1c","IPY_MODEL_b7b254799dcf42abad93ec967c6390ee"],"layout":"IPY_MODEL_512e9c26893c4863a13fc350f300d298"}},"5cb6355a47564561905cb85d5e2a215d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"614f2d66fd344a25b7b6383980cd7155":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66ca21cf60e04146a6e49c54c4d907cd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f2ac7f41df941d09b5fafca7a33fc80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"70fb7bc7b0df400bae48129c0122fdc7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72e836e1b0de4672b9c146115c9e80d2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"773207ff49ed462198b8069b4a3599a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a3fcd5d41954cd792dd1a090ea35675":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_206c03deb81246f9a29b7c67068890ff","IPY_MODEL_ba0a7cb82bb84eaa86ef1771708b15fc","IPY_MODEL_b302ad0ebfa549d694f6507a405f26da"],"layout":"IPY_MODEL_e68f719f28424268860b10cce8c851f0"}},"7bb1955df5bd4fa488f6db6bd953d7f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7dc2510ff41447a88c9616fc910c2fcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_66ca21cf60e04146a6e49c54c4d907cd","placeholder":"​","style":"IPY_MODEL_5cb6355a47564561905cb85d5e2a215d","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"7f2cd69196c54639a70a7291faa87964":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80f46bd96ade485495becef95abb7e1c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a124fbb4489646eaa93712527197f296","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3d8f28d0299a43ffba66f77ac5af2445","value":28}},"915bff8ea4fd4fa387abdb9025b24fcb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a8b59aa137742909bca6d6b85d3e0a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe037727e6344d0ebc7666336b9d8c92","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_773207ff49ed462198b8069b4a3599a2","value":570}},"a124fbb4489646eaa93712527197f296":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b302ad0ebfa549d694f6507a405f26da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e69aa654b6f433db150102481799868","placeholder":"​","style":"IPY_MODEL_4bc963ef40b7451e8bbc5e8bc2272de3","value":" 440M/440M [00:27&lt;00:00, 16.3MB/s]"}},"b7b254799dcf42abad93ec967c6390ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f2cd69196c54639a70a7291faa87964","placeholder":"​","style":"IPY_MODEL_7bb1955df5bd4fa488f6db6bd953d7f4","value":" 28.0/28.0 [00:00&lt;00:00, 1.30kB/s]"}},"b91ce17218374baf88dd6151be2646b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba0a7cb82bb84eaa86ef1771708b15fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e07a1e5a23004236923bc726eb89587f","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c1e1d5955ccd4576a6bd3835dd2dff80","value":440473133}},"ba4a9ecb04b847c5ba286c65c7c30cef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f3a32a5b1d6946bc862af6ae960f5476","placeholder":"​","style":"IPY_MODEL_c5c5bc8e5a2048b881059ab439c0791a","value":" 570/570 [00:00&lt;00:00, 24.8kB/s]"}},"c1e1d5955ccd4576a6bd3835dd2dff80":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c5c5bc8e5a2048b881059ab439c0791a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c87f6fac4e7f43168f0ed3217b8311e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b91ce17218374baf88dd6151be2646b1","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6f2ac7f41df941d09b5fafca7a33fc80","value":231508}},"ca5fe4cb9df646509879351fe57d3b34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1a2435a3ab141f19c5f75e1b3522a21":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df58528b10d04385a92883565977b3aa","placeholder":"​","style":"IPY_MODEL_72e836e1b0de4672b9c146115c9e80d2","value":" 232k/232k [00:00&lt;00:00, 4.19MB/s]"}},"df58528b10d04385a92883565977b3aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e07a1e5a23004236923bc726eb89587f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e68f719f28424268860b10cce8c851f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f14076efef7848daa057e9212fe4a10c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f3a32a5b1d6946bc862af6ae960f5476":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc16a62aa2da45ce9d0033a1038365a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe037727e6344d0ebc7666336b9d8c92":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
